{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%matplotlib\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema\n",
    "import itertools\n",
    "import scipy.fftpack as fft\n",
    "from scipy.stats import norm, skew, kurtosis\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from helper_functions import getListOfFiles, getCSV, getStatistics, remap_interval\n",
    "from operator import itemgetter\n",
    "from detect_peaks import detect_peaks\n",
    "from gaussian_kde import gaussian_kde\n",
    "import mean_shift as ms\n",
    "import mean_shift_utils as ms_utils\n",
    "import meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 87 mat Files found!\n"
     ]
    }
   ],
   "source": [
    "acc_axes = ['x','y','z']\n",
    "mat_dir = '../data/multi_split'\n",
    "sym_dir = os.path.join(mat_dir)#, 'symbolization')\n",
    "files = [f.split('__')[1] for f in getListOfFiles(sym_dir, \".mat\")]\n",
    "print \">> {} mat Files found!\".format(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = OrderedDict()\n",
    "previous_files = None\n",
    "\n",
    "for ind, current_file in enumerate(files):\n",
    "    file_data = {}\n",
    "    for axis in acc_axes:\n",
    "        ## load correspoding data structure\n",
    "        mat_content = sio.loadmat(os.path.join(sym_dir, axis+'__'+current_file))\n",
    "        data = mat_content['exp']\n",
    "        val = data[0,0]\n",
    "\n",
    "        ## grab the data\n",
    "        ts = [x[0] for x in val['sig_data']]\n",
    "        splitpoints = val['split_cand'][0].tolist()\n",
    "        weights =  val['weights'][0].tolist()\n",
    "\n",
    "        # structuring individual axis data\n",
    "        file_data[axis+'.ts'] = ts\n",
    "        file_data[axis+'.splits'] = splitpoints[:-1]\n",
    "        file_data[axis+'.weights'] = weights[:-1]\n",
    "    dataset[current_file] = file_data\n",
    "print '>> {} files loaded'.format(len(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figsize(20,6)\n",
    "file_number = 0\n",
    "figsize(16,3)\n",
    "markers = ['v', '^', '*']\n",
    "for i,axis in enumerate(acc_axes):\n",
    "    plt.plot(dataset[files[file_number]][axis+'.ts'], label= axis)\n",
    "    y = np.random.rand(1,len(dataset[files[file_number]][axis+'.splits']))\n",
    "    plt.scatter(dataset[files[file_number]][axis+'.splits'],y, marker=markers[i], label=axis+' split points')\n",
    "plt.title('Data for ' + files[file_number])\n",
    "plt.xlim(0,plt.xlim()[1])\n",
    "plt.ylim(-5,5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the separation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ma_mi_list = {}\n",
    "cluster_centers = {}\n",
    "tau = 1\n",
    "for ind, current_file in enumerate(dataset.keys()):\n",
    "    fig=figure(figsize=(15,8))\n",
    "    ax1=fig.add_subplot(311)\n",
    "    \n",
    "    split_cand_list = []\n",
    "    weigth_list = []\n",
    "    data = dataset[current_file]\n",
    "    for axis in acc_axes:\n",
    "        split_cand_list += [(s,axis) for s in data[axis+'.splits']]\n",
    "        weigth_list     += [(w,axis) for w in data[axis+'.weights']]\n",
    "\n",
    "    weights = np.array([w[0] for w in weigth_list], np.float)\n",
    "    samples = np.array([s[0] for s in split_cand_list])\n",
    "\n",
    "    min, max = 0,len(data['x.ts'])\n",
    "    x = np.linspace(min, max, max)\n",
    "\n",
    "    clusters = []\n",
    "\n",
    "    #Construct a KDE and plot it\n",
    "    bws = [0.03]#0.01, 0.02, 0.03, 0.06, 0.1]\n",
    "    ma = None\n",
    "    mi = None\n",
    "    for bw in bws:\n",
    "        pdf = gaussian_kde(samples, bw_method=bw, weights=weights)\n",
    "        y = pdf(x)\n",
    "        ax1.plot(x, y, label='weighted kde, bw='+ str(bw))\n",
    "        # mi = list of minimum indices in y.\n",
    "        # ma = list of maximum indices in y.\n",
    "        mi, ma = argrelextrema(y, np.less)[0], argrelextrema(y, np.greater)[0]\n",
    "        #print \"Minima:\", x[mi]\n",
    "        #print \"Maxima:\", x[ma]\n",
    "\n",
    "        samples2 = []\n",
    "        for s,w in zip(split_cand_list,weigth_list):\n",
    "            samples2.append((s[0],w[0],s[1]))\n",
    "        samples2 = np.array(samples2)\n",
    "\n",
    "        for xc in x[mi]:\n",
    "            ax1.axvline(x=xc, color='k', linestyle='-.')\n",
    "\n",
    "        ## Get clusters by considering each one as a region between minimas. \n",
    "        # Count the itens for each cluster region. O(K), where K are regions defined by minimas.\n",
    "        for m in range(len(mi)):\n",
    "            if m == 0:\n",
    "                clusters.append(samples2[samples < x[mi[m]]].tolist())\n",
    "            else:\n",
    "                clusters.append(samples2[(samples >= x[mi[m-1]]) * (samples <= x[mi[m]])].tolist())\n",
    "\n",
    "        ax1.plot(x[ma], y[ma], 'g^',x[mi], y[mi], 'rv')\n",
    "\n",
    "    ## Saving maxima e minima\n",
    "    ma_mi_list[current_file] = {'mi': mi, 'ma': ma}\n",
    "    \n",
    "    energies = []\n",
    "    total_energy = 0\n",
    "    for ind,c in enumerate(clusters):\n",
    "        accumulator = 0\n",
    "        for elem in c:\n",
    "            accumulator += float(elem[1])\n",
    "        total_energy += accumulator\n",
    "        energies.append((accumulator,ind))\n",
    "\n",
    "    #energies = [(e/total_energy,ind) for inx,e in enumerate(energies)]\n",
    "\n",
    "    #print 'Total energy: {}'.format(total_energy)\n",
    "    #print 'Total energy after normalization: {}'.format(sum([e[0] for e in energies]))\n",
    "    energies.sort(reverse=True, key=lambda tup: tup[0])\n",
    "\n",
    "    #Plot the split candidates\n",
    "    markers = ['o','x','^']\n",
    "    colors = ['b', 'r','m']\n",
    "    for i,axis in enumerate(acc_axes):\n",
    "        ax1.scatter(data[axis+'.splits'], np.zeros_like(data[axis+'.splits']),\n",
    "                    label='Split candidate for {}'.format(axis),\n",
    "                    marker=markers[i], color='m')\n",
    "\n",
    "    #Boiler plate\n",
    "    plt.xticks([s[0] for s in split_cand_list],rotation = 90, fontsize=8)\n",
    "    ax1.set_title('Split point gaussian kernel density estimation for {}'.format(current_file))\n",
    "    ax1.set_xlabel('Variable')\n",
    "    ax1.set_ylabel('Density')\n",
    "    plt.legend(loc='best', frameon=False)\n",
    "\n",
    "    final_clusters = []\n",
    "    accumulator = 0\n",
    "    for e in energies:\n",
    "        accumulator += e[0]\n",
    "        if accumulator > tau*total_energy:\n",
    "            break\n",
    "        else:\n",
    "            final_clusters.append(e[1])\n",
    "\n",
    "    #print 'Total: {}, Accumulator: {}, Threshold: {}'.format(total_energy,accumulator,tau*total_energy)\n",
    "    cluster_centers[current_file] = x[ma[final_clusters]]\n",
    "\n",
    "    ax2 = fig.add_subplot(312, sharex=ax1)\n",
    "    ax2.plot(x, y, label='weighted kde, bw='+ str(bw))\n",
    "    for xc in x[ma[final_clusters]]:\n",
    "            ax2.axvline(x=xc, color='k', linestyle='-.')\n",
    "    ax2.set_ylim(-0.0003,ax2.get_ylim()[1])\n",
    "    plt.xticks([s[0] for s in split_cand_list],rotation = 90, fontsize=8)\n",
    "    plt.legend(loc='best', frameon=False)\n",
    "\n",
    "    ax3 = fig.add_subplot(313, sharex=ax1)\n",
    "    for axis in acc_axes:\n",
    "        ax3.plot(data[axis+'.ts'], label=axis)\n",
    "\n",
    "    for xc in x[ma[final_clusters]]:\n",
    "        ax3.axvline(x=xc, color='k', linestyle='-.')     \n",
    "\n",
    "    plt.xticks(x[ma[final_clusters]],rotation = 90, fontsize=8)\n",
    "    plt.legend(loc='best', frameon=False)\n",
    "    plt.tight_layout()\n",
    "    #plt.ylim(-0.0003,plt.ylim()[1])\n",
    "    plt.xlim(min,max)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Getting the segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_segments(filename,maximas):\n",
    "    data = dataset[filename]\n",
    "    x_segments = []\n",
    "    y_segments = []\n",
    "    z_segments = []\n",
    "    alignments = []\n",
    "    \n",
    "    min, max = 0,len(data['x.ts'])\n",
    "    x = np.linspace(min, max, max)\n",
    "    \n",
    "    centers = [int(i) for i in sorted(cluster_centers[filename])]\n",
    "    x_data = np.array(data['x.ts'])\n",
    "    y_data = np.array(data['y.ts'])\n",
    "    z_data = np.array(data['z.ts'])\n",
    "    for i in range(len(centers)):\n",
    "            if i == 0:\n",
    "                x_segments.append(x_data[:int(centers[i])])\n",
    "                y_segments.append(y_data[:int(centers[i])])   \n",
    "                z_segments.append(z_data[:int(centers[i])])\n",
    "                alignments.append(0)\n",
    "            elif i == (len(centers)-1):\n",
    "                x_segments.append(x_data[int(centers[i-1]):int(centers[i])].tolist())\n",
    "                x_segments.append(x_data[int(centers[i]):].tolist())\n",
    "                y_segments.append(y_data[int(centers[i-1]):int(centers[i])].tolist())\n",
    "                y_segments.append(y_data[int(centers[i]):].tolist())\n",
    "                z_segments.append(z_data[int(centers[i-1]):int(centers[i])].tolist())\n",
    "                z_segments.append(z_data[int(centers[i]):].tolist())\n",
    "\n",
    "                alignments.append(centers[i-1])\n",
    "                alignments.append(centers[i])\n",
    "            else:\n",
    "                x_segments.append(x_data[int(centers[i-1]):int(centers[i])].tolist())\n",
    "                y_segments.append(y_data[int(centers[i-1]):int(centers[i])].tolist())\n",
    "                z_segments.append(z_data[int(centers[i-1]):int(centers[i])].tolist())\n",
    "                alignments.append(centers[i-1])\n",
    "    return x_segments, y_segments, z_segments, alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking data segments equality with original time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_segments = []\n",
    "y_segments = []\n",
    "z_segments = []\n",
    "alignments = []\n",
    "file_map_list   = []\n",
    "\n",
    "for f in dataset.keys():\n",
    "    x_seg, y_seg, z_seg, aligns = get_segments(f,ma_mi_list[f]['ma'])\n",
    "    ### testing equality\n",
    "    try:\n",
    "        assert list(itertools.chain.from_iterable(x_seg)) == dataset[f]['x.ts']\n",
    "        assert list(itertools.chain.from_iterable(y_seg)) == dataset[f]['y.ts']\n",
    "        assert list(itertools.chain.from_iterable(z_seg)) == dataset[f]['z.ts']\n",
    "    except AssertionError:\n",
    "        _, _, tb = sys.exc_info()\n",
    "        traceback.print_tb(tb) # Fixed format\n",
    "        tb_info = traceback.extract_tb(tb)\n",
    "        filename, line, func, text = tb_info[-1]\n",
    "        print('An error occurred on line {} in statement {}'.format(line, text))\n",
    "        print('Equivalence test failed for file {}. ABORTING'.format(f))\n",
    "        break\n",
    "    \n",
    "    for i in range(len(x_seg)):\n",
    "        x_segments.append(x_seg[i])\n",
    "        y_segments.append(y_seg[i])\n",
    "        z_segments.append(z_seg[i])\n",
    "        alignments.append(aligns[i])\n",
    "        file_map_list.append('.'.join(f.split('.')[:-1]))\n",
    "    \n",
    "print 'ALL files PASSED on equivalence tests. This means the segmentation does not lose data!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framming corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = {\n",
    "      'x'    : x_segments,\n",
    "      'y'    : y_segments,\n",
    "      'z'    : z_segments,\n",
    "      'align' : alignments,\n",
    "      'file' : file_map_list\n",
    "     }\n",
    "\n",
    "frame = pd.DataFrame(df, index = [range(len(file_map_list))] , columns = ['x','y','z','align','file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting model to pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the file for writing\n",
    "pkl_file_name = 'segments.pkl'\n",
    "file_object = open(pkl_file_name,'wb')\n",
    "pickle.dump(frame,file_object)\n",
    "file_object.close()\n",
    "print 'pickle DONE!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(15,3))\n",
    "filename = dataset.keys()[0]\n",
    "for xc in cluster_centers[filename]:\n",
    "    plt.axvline(x=xc, color='m', linestyle='-.')\n",
    "\n",
    "x = list(itertools.chain.from_iterable(frame.loc[frame['file'] == '.'.join(filename.split('.')[:-1])]['x'].tolist()))\n",
    "y = list(itertools.chain.from_iterable(frame.loc[frame['file'] == '.'.join(filename.split('.')[:-1])]['y'].tolist()))\n",
    "z = list(itertools.chain.from_iterable(frame.loc[frame['file'] == '.'.join(filename.split('.')[:-1])]['z'].tolist()))\n",
    "plt.plot(x,'-', label='x')\n",
    "plt.plot(y, '-', label='y')\n",
    "plt.plot(z, '-', label='z')\n",
    "plt.title(\"Reconstructed file {}\".format(filename))\n",
    "plt.legend()\n",
    "plt.xticks(cluster_centers[filename], rotation = 90)\n",
    "#plt.ylim(-6,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandwith selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ma_mi_list = {}\n",
    "cluster_centers = {}\n",
    "tau = 1#0.95\n",
    "current_file = dataset.keys()[0]\n",
    "fig=figure(figsize=(15,10))\n",
    "ax1=fig.add_subplot(311)\n",
    "\n",
    "split_cand_list = []\n",
    "weigth_list = []\n",
    "data = dataset[current_file]\n",
    "for axis in acc_axes:\n",
    "    split_cand_list += [(s,axis) for s in data[axis+'.splits']]\n",
    "    weigth_list     += [(w,axis) for w in data[axis+'.weights']]\n",
    "\n",
    "weights = np.array([w[0] for w in weigth_list], np.float)\n",
    "samples = np.array([s[0] for s in split_cand_list])\n",
    "\n",
    "min, max = 0,len(data['x.ts'])\n",
    "x = np.linspace(min, max, max)\n",
    "\n",
    "clusters = []\n",
    "\n",
    "#Construct a KDE and plot it\n",
    "bws = [0.03,0.01, 0.02, 0.03, 0.06]\n",
    "for bw in bws:\n",
    "    pdf = gaussian_kde(samples, bw_method=bw, weights=weights)\n",
    "    y = pdf(x)\n",
    "    ax1.plot(x, y, label='weighted kde, bw='+ str(bw))\n",
    "\n",
    "\n",
    "#Plot the split candidates\n",
    "markers = ['o','x','^']\n",
    "colors = ['b', 'r','m']\n",
    "for i,axis in enumerate(acc_axes):\n",
    "    ax1.scatter(data[axis+'.splits'], np.zeros_like(data[axis+'.splits']),\n",
    "                label='Split candidate for {}'.format(axis),\n",
    "                marker=markers[i], color='m')\n",
    "\n",
    "#Boiler plate\n",
    "plt.xticks([s[0] for s in split_cand_list],rotation = 90, fontsize=8)\n",
    "ax1.set_title('Split point gaussian kernel density estimation for {}'.format(current_file))\n",
    "ax1.set_xlabel('Cutting point')\n",
    "ax1.set_ylabel('Density')\n",
    "plt.legend(loc='best', frameon=False)\n",
    "\n",
    "ax3 = fig.add_subplot(312, sharex=ax1)\n",
    "for axis in acc_axes:\n",
    "    ax3.plot(data[axis+'.ts'], label=axis)   \n",
    "\n",
    "plt.legend(loc='best', frameon=False)\n",
    "plt.tight_layout()\n",
    "ax1.set_xlabel('Acceleration')\n",
    "ax1.set_ylabel('Cutting point')\n",
    "plt.xlim(min,max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 6)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resframe = []\n",
    "with open(\"../pickle/annotation.pkl\",'r') as f:\n",
    "    resframe = pickle.load(f)\n",
    "resframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised dataset dim: (286, 6)\n",
      "Columns: ['x', 'y', 'z', 'align', 'file', 'tag']\n",
      "(455, 286)\n",
      "(455, 286)\n",
      "(455, 286)\n"
     ]
    }
   ],
   "source": [
    "x_df = None\n",
    "y_df = None\n",
    "z_df = None\n",
    "sup_resframe = resframe[resframe['tag'] !=\"\"]\n",
    "print 'Supervised dataset dim: {}'.format(sup_resframe.shape)\n",
    "print 'Columns: {}'.format(sup_resframe.columns.tolist())\n",
    "for df in sup_resframe.itertuples():\n",
    "    x = pd.DataFrame({df[0]:df[1]})\n",
    "    y = pd.DataFrame({df[0]:df[2]})\n",
    "    z = pd.DataFrame({df[0]:df[3]})\n",
    "    if df[0] == 0:\n",
    "        x_df = x\n",
    "        y_df = y\n",
    "        z_df = z\n",
    "    else:\n",
    "        x_df = pd.concat([x_df,x], ignore_index=True, axis=1)\n",
    "        y_df = pd.concat([y_df,y], ignore_index=True, axis=1)\n",
    "        z_df = pd.concat([z_df,z], ignore_index=True, axis=1)\n",
    "#x_df = pd.concat([x_df,sup_resframe.loc[:,'file':'tag']], ignore_index=True, axis=1)\n",
    "#x_df.columns = x_df.columns[:-2].tolist() + ['file','tag']\n",
    "#y_df = pd.concat([y_df,sup_resframe.loc[:,'file':'tag']], ignore_index=True, axis=1)\n",
    "#y_df.columns = y_df.columns[:-2].tolist() + ['file','tag']\n",
    "#z_df = pd.concat([z_df,sup_resframe.loc[:,'file':'tag']], ignore_index=True, axis=1)\n",
    "#z_df.columns = z_df.columns[:-2].tolist() + ['file','tag']\n",
    "print x_df.shape #all x's + file, tag\n",
    "print y_df.shape #all y's + file, tag\n",
    "print z_df.shape #all z's + file, tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised: (286, 6)\n"
     ]
    }
   ],
   "source": [
    "supervised = resframe[resframe['tag'] !=\"\"]\n",
    "print 'Supervised: {}'.format(supervised.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised: (285, 6)\n"
     ]
    }
   ],
   "source": [
    "unsupervised = resframe[resframe['tag'] ==\"\"]\n",
    "print 'Unsupervised: {}'.format(unsupervised.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading metafeatures dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import meta_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function_dispatcher = {\n",
    "    \"mean\"     : meta_features.mean,\n",
    "    \"std\"      : meta_features.std,\n",
    "    \"max\"      : meta_features.max_value,\n",
    "    \"min\"      : meta_features.min_value,\n",
    "    \"mad\"      : meta_features.mad,\n",
    "    \"sma\"      : meta_features.sma,\n",
    "    \"iqr\"      : meta_features.iqr,\n",
    "    \"energy\"   : meta_features.energy,\n",
    "    \"fft_energy\"   : meta_features.fft_energy,\n",
    "    \"maxInds\"  : meta_features.maxInds,\n",
    "    \"meanFreq\" : meta_features.meanFreq,\n",
    "    \"skewness\" : meta_features.skewness,\n",
    "    \"kurtosis\" : meta_features.kurtos,\n",
    "    \"freq_skewness\" : meta_features.freq_skewness,\n",
    "    \"freq_kurtosis\" : meta_features.freq_kurtos,\n",
    "    \"num_peaks\"     : meta_features.num_peaks,\n",
    "    \"moving_rmsV1\"  : meta_features.moving_rmsV1,\n",
    "    \"rms\"           : meta_features.rms,\n",
    "    \"max_min\"       : meta_features.max_min,\n",
    "    \"pse\"           : meta_features.pse\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metafeat_vector(segment, mf=[\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\n",
    "                                        \"iqr\",\"energy\",\"maxInds\",\"meanFreq\",\"skewness\",\"kurtosis\"]):\n",
    "    \"\"\"\n",
    "        Compute metafeatures from segment data.\n",
    "    \n",
    "        segment : the time series segment\n",
    "        mf      : list of metafeatures functions to be computed on the segment data.\n",
    "    \"\"\"\n",
    "    \n",
    "    meta_vector = OrderedDict()\n",
    "\n",
    "    for f in mf:\n",
    "        try:\n",
    "            func = function_dispatcher[f]          # retrieve function\n",
    "            meta_vector[f] = func(segment)    # compute function on segment.\n",
    "        except KeyError:\n",
    "            raise ValueError('Invalid function: {}'.format(f))\n",
    "\n",
    "    return meta_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### windowing function\n",
    "def win_function(data):\n",
    "    window_rads = np.linspace(0, np.pi, len(data))\n",
    "    window = np.sin(window_rads)**2\n",
    "    return data * window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the corresponding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#{u'High_level': u'Blocking-Dodging'} 30\n",
    "#        {u'High_level': u'Inactive'} 7\n",
    "#  {u'High_level': u'Locally-Moving'} 78\n",
    "#         {u'High_level': u'Running'} 73\n",
    "#       {u'High_level': u'Sprinting'} 27\n",
    "#    {u'High_level': u'Stop-Running'} 36\n",
    "#         {u'High_level': u'Walking'} 35\n",
    "\n",
    "##### LOADING THE DATA ################\n",
    "topics = (\"{u'High_level': u'Blocking-Dodging'}\",\n",
    "          \"{u'High_level': u'Inactive'}\",\n",
    "          \"{u'High_level': u'Locally-Moving'}\",\n",
    "          \"{u'High_level': u'Running'}\",\n",
    "          \"{u'High_level': u'Sprinting'}\",\n",
    "          \"{u'High_level': u'Stop-Running'}\",\n",
    "          \"{u'High_level': u'Walking'}\")\n",
    "\n",
    "topic = topics[3]\n",
    "\n",
    "Xs = []\n",
    "Ys = []\n",
    "Zs = []\n",
    "\n",
    "for it, topic in enumerate(topics):\n",
    "    x_sig_segments = resframe[resframe['tag']== topic]['x'].tolist() \n",
    "    y_sig_segments = resframe[resframe['tag']== topic]['y'].tolist()\n",
    "    z_sig_segments = resframe[resframe['tag']== topic]['z'].tolist()\n",
    "\n",
    "    ##apply windowing function\n",
    "    x_sig_segments = [win_function(x_sig) for x_sig in x_sig_segments]\n",
    "    y_sig_segments = [win_function(y_sig) for y_sig in y_sig_segments]\n",
    "    z_sig_segments = [win_function(z_sig) for z_sig in z_sig_segments]\n",
    "\n",
    "    ##### COMPUTING METAFEATURES ###########\n",
    "    ## metafeatures list to be computed\n",
    "    #to_compute = [\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\"iqr\",\"rms\",\"maxInds\",\"skewness\",\"kurtosis\",\"freq_skewness\",\"freq_kurtosis\"]\n",
    "    #to_compute = [\"mean\",\"std\",\"mad\",\"sma\",\"iqr\",\"skewness\",\"kurtosis\",\"maxInds\",\"rms\",\"num_peaks\"]\n",
    "    to_compute = [\"mean\", \"pse\", \"sma\"]\n",
    "\n",
    "    x_meta_fts = []\n",
    "    y_meta_fts = []\n",
    "    z_meta_fts = []\n",
    "    \n",
    "    for s in range(len(z_sig_segments)):\n",
    "        x_meta_fts.append(get_metafeat_vector(x_sig_segments[s],mf=to_compute).values())\n",
    "        y_meta_fts.append(get_metafeat_vector(y_sig_segments[s],mf=to_compute).values())\n",
    "        z_meta_fts.append(get_metafeat_vector(z_sig_segments[s],mf=to_compute).values())\n",
    "        xy_corr     = meta_features.correlation(x_sig_segments[s], y_sig_segments[s])\n",
    "        xz_corr     = meta_features.correlation(x_sig_segments[s], z_sig_segments[s])\n",
    "        yz_corr     = meta_features.correlation(y_sig_segments[s], z_sig_segments[s])\n",
    "        \n",
    "\n",
    "    labels = pd.DataFrame(np.array([topic.split(\"'\")[-2] for t in range(len(z_sig_segments))]), columns=['label'])\n",
    "    X = pd.DataFrame(np.array(x_meta_fts), columns=to_compute)\n",
    "    Y = pd.DataFrame(np.array(y_meta_fts), columns=to_compute)\n",
    "    Z = pd.DataFrame(np.array(z_meta_fts), columns=to_compute)\n",
    "    \n",
    "    Xs.append(pd.concat([X, labels], axis=1, join_axes=[X.index]))\n",
    "    Ys.append(pd.concat([Y, labels], axis=1, join_axes=[Y.index]))\n",
    "    Zs.append(pd.concat([Z, labels], axis=1, join_axes=[Z.index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### PLOTTING RESULTS #####\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "# We choose a color palette with seaborn.\n",
    "palette = np.array(sns.color_palette(\"hls\", 8))\n",
    "\n",
    "fig=plt.figure(figsize=(8,6))\n",
    "#ax=fig.add_subplot(111)\n",
    "ax = Axes3D(fig)\n",
    "for it,X in enumerate(Xs):\n",
    "    ax.scatter(X[to_compute[0]], X[to_compute[1]], X[to_compute[2]], c=palette[it],label=topics[it].split(\"'\")[-2])\n",
    "    #plt.savefig('result_'+topic.split(\"'\")[-2]+\".png\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_map = {\"Blocking-Dodging\": 0,    #30\n",
    "              \"Inactive\": 1,            #7\n",
    "              \"Locally-Moving\": 2,      #78\n",
    "              \"Running\": 3,             #73\n",
    "              \"Sprinting\": 4,           #27\n",
    "              \"Stop-Running\": 5,        #36\n",
    "              \"Walking\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286,)\n",
      "(286, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack([x.as_matrix()[:,:-1]\n",
    "               for x in Zs])\n",
    "\n",
    "y = np.hstack([x['label'].as_matrix()\n",
    "               for x in Zs])\n",
    "\n",
    "print y.shape\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=3)\n",
    "X_pca = sklearn_pca.fit_transform(X)\n",
    "print X_pca.shape\n",
    "\n",
    "def plot_pca():\n",
    "\n",
    "    fig=plt.figure(figsize=(8,6))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    for label,marker,color in zip(\n",
    "        topic_map.keys(),('^', 's', 'o','<','>','+'),[palette[it] for it in range(6)]):\n",
    "\n",
    "        #ax.scatter(X[to_compute[0]], X[to_compute[1]], X[to_compute[2]], c=palette[it],label=topics[it].split(\"'\")[-2])\n",
    "        ax.scatter(X_pca[:,0][y == label],\n",
    "                X_pca[:,1][y == label],\n",
    "                X_pca[:,2][y == label],\n",
    "                marker=marker,\n",
    "                color=color,\n",
    "                alpha=0.5,\n",
    "                label=label\n",
    "                )\n",
    "\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "\n",
    "    leg = ax.legend(loc='upper right', fancybox=True)\n",
    "    #leg.get_frame().set_alpha(0.5)\n",
    "    ax.set_title('PCA: Iris projection onto the first 2 principal components')\n",
    "\n",
    "    # hide axis ticks\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    #ax.spines[\"top\"].set_visible(False)  \n",
    "    #ax.spines[\"right\"].set_visible(False)\n",
    "    #ax.spines[\"bottom\"].set_visible(False)\n",
    "    #ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    plt.tight_layout\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LDA\n",
    "sklearn_lda = LDA(n_components=2)\n",
    "X_lda_sklearn = sklearn_lda.fit_transform(X_pca, y)\n",
    "\n",
    "def plot_scikit_lda(X, title):\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for label,marker,color in zip(\n",
    "        topic_map.keys(),('^', 's', 'o','<','>','+'),[palette[it] for it in range(6)]):\n",
    "\n",
    "        plt.scatter(x=X[:,0][y == label],\n",
    "                    y=X[:,1][y == label] * -1, # flip the figure\n",
    "                    marker=marker,\n",
    "                    color=color,\n",
    "                    alpha=0.5,\n",
    "                    label=label)\n",
    "\n",
    "    plt.xlabel('LD1')\n",
    "    plt.ylabel('LD2')\n",
    "\n",
    "    leg = plt.legend(loc='upper right', fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.title(title)\n",
    "\n",
    "    # hide axis ticks\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_step_lda():\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for label,marker,color in zip(\n",
    "        range(1,4),('^', 's', 'o'),('blue', 'red', 'green')):\n",
    "\n",
    "        plt.scatter(x=X_lda[:,0].real[y == label],\n",
    "                y=X_lda[:,1].real[y == label],\n",
    "                marker=marker,\n",
    "                color=color,\n",
    "                alpha=0.5,\n",
    "                label=label_dict[label]\n",
    "                )\n",
    "\n",
    "    plt.xlabel('LD1')\n",
    "    plt.ylabel('LD2')\n",
    "\n",
    "    leg = plt.legend(loc='upper right', fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.title('LDA: Iris projection onto the first 2 linear discriminants')\n",
    "\n",
    "    # hide axis ticks\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_step_lda()\n",
    "plot_scikit_lda(X_lda_sklearn, title='Default LDA via scikit-learn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 5.62 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n"
     ]
    }
   ],
   "source": [
    "import scipy.fftpack as fft\n",
    "#fig = plt.figure(figsize=[12,7])\n",
    "#ax0 = plt.subplot(121)\n",
    "\n",
    "#t =  [0,10,20,30,40,50,60,70,80,90]; # time scale\n",
    "#x = [10,120,130,120,120,100,123,456,78,89]; # time series\n",
    "frequences = []\n",
    "topic = topics[4]\n",
    "t_freq = []\n",
    "for d in resframe[resframe['tag']== topic]['x'].tolist():\n",
    "    Fs = 45 # sampling frequency 1 kHz\n",
    "    x = d\n",
    "    t = range(len(x))\n",
    "    x = x - np.mean(x);                                            # <= ADDED LINE\n",
    "    #ax0.plot(t,x)\n",
    "    #ax0.grid()\n",
    "    #ax0.set_title('Time series')\n",
    "\n",
    "    nfft = 16 # next larger power of 2\n",
    "    y = fft.fft(x,n=nfft)  # Fast Fourier Transform\n",
    "    ysp = np.abs(y**2); # raw power spectrum density\n",
    "    yhalf = ysp[:int(nfft/2)]; # half-spectrum\n",
    "    v = np.max(yhalf); # find maximum\n",
    "    k = np.argmax(yhalf)\n",
    "    f_scale = np.array(range(int(nfft/2)))* Fs/nfft;\n",
    "\n",
    "    T = 1./Fs          #the period, the sample time, the time after which each data come.\n",
    "    t  = np.linspace(0,len(x)*T,len(x)) # N_samps*T (#samples x sample period) is the signal time.\n",
    "    freq_axis = np.arange(0,Fs,Fs/nfft)\n",
    "\n",
    "    ##### FFT of the signal #####\n",
    "    #plt.subplots_adjust(hspace=0.5, wspace= 0.4)\n",
    "    #ax = plt.subplot(122)\n",
    "    #pt, = ax.plot(freq_axis,ysp, lw=2.0, c='b')\n",
    "    #p = plt.Rectangle((Fs/2, 0), Fs/2, ax.get_ylim()[1], facecolor=\"grey\", fill=True, alpha=0.75, hatch=\"/\", zorder=3)\n",
    "    #ax.add_patch(p)\n",
    "    #ax.set_xlim((ax.get_xlim()[0],Fs))\n",
    "    #ax.set_title('FFT - signal', fontsize= 16, fontweight=\"bold\")\n",
    "    #ax.set_ylabel('FFT magnitude (power)')\n",
    "    #ax.set_xlabel('Frequency (Hz)')\n",
    "    #plt.legend((p,), ('excluded',))\n",
    "    #plt.grid()\n",
    "\n",
    "    freq = k*(Fs/nfft)\n",
    "    if freq == k:\n",
    "        plt.plot(t,x)\n",
    "    print 'Dominant freq.: {:.2f} Hz'.format(k*(Fs/nfft))\n",
    "    #fprintf('Frequency step (resolution) = %f Hznn\\n', f_scale(2))\n",
    "    t_freq.append(freq)\n",
    "frequences.append(t_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,f in enumerate(frequences):\n",
    "    print i\n",
    "    plt.hist(f, color=palette[i], alpha=0.9, label=topics[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 2.81 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 5.62 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "Dominant freq.: 0.00 Hz\n",
      "(35, 8)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Unknown property c",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-072015faf9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FFT - signal {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FFT magnitude (power)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1818\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6197\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6198\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6199\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6200\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown property %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mchanged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Unknown property c"
     ]
    }
   ],
   "source": [
    "import scipy.fftpack as fft\n",
    "fig = plt.figure(figsize=[12,7])\n",
    "ax0 = plt.subplot(121)\n",
    "\n",
    "topic = topics[6]\n",
    "data = resframe[resframe['tag']== topic]['x'].tolist()\n",
    "topic_bins = []\n",
    "t_freq = []\n",
    "for i,x in enumerate(data):\n",
    "    #t =  [0,10,20,30,40,50,60,70,80,90]; # time scale\n",
    "    #x = [10,120,130,120,120,100,123,456,78,89]; # time series\n",
    "    Fs = 45 # sampling frequency 1 kHz\n",
    "    t = range(len(x))\n",
    "    x = x - np.mean(x);                                            # <= ADDED LINE\n",
    "    ax0.plot(t,x)\n",
    "    ax0.grid()\n",
    "    ax0.set_title('Time series')\n",
    "\n",
    "    nfft = 16 # next larger power of 2\n",
    "    y = fft.fft(x,n=nfft)  # Fast Fourier Transform\n",
    "    ysp = np.abs(y**2); # raw power spectrum density\n",
    "    yhalf = ysp[:int(nfft/2)]; # half-spectrum\n",
    "\n",
    "    v = np.max(yhalf); # find maximum\n",
    "    k = np.argmax(yhalf)\n",
    "    f_scale = np.array(range(int(nfft/2)))* Fs/nfft;\n",
    "\n",
    "    T = 1./Fs          #the period, the sample time, the time after which each data come.\n",
    "    t  = np.linspace(0,len(x)*T,len(x)) # N_samps*T (#samples x sample period) is the signal time.\n",
    "    freq_axis = np.arange(0,Fs,Fs/nfft)\n",
    "\n",
    "    topic_bins.append(yhalf)\n",
    "    freq = k*(Fs/nfft)\n",
    "    print 'Dominant freq.: {:.2f} Hz'.format(k*(Fs/nfft))\n",
    "\n",
    "##### FFT of the signal #####\n",
    "the_bins = np.array(topic_bins)\n",
    "print the_bins.shape\n",
    "plt.subplots_adjust(hspace=0.5, wspace= 0.4)\n",
    "ax = plt.subplot(122)\n",
    "pt, = ax.hist(the_bins, lw=2.0, c=palette[i%8])\n",
    "ax.set_title('FFT - signal {}'.format(topic.split(\"'\")[-2]), fontsize= 16, fontweight=\"bold\")\n",
    "ax.set_ylabel('FFT magnitude (power)')\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "plt.legend((p,), ('excluded',))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
