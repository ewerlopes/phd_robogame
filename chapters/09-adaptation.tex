\chapter{A theoretical model for adjusting robot playing behavior}\label{ch:adaptation}
\epigraph{In theory, there is no difference between theory and practice. But in practice, there is. 
}{--- Benjamin Brewster}

The ultimate goal in a~\gls{pirg} application is to be able to present some degree of behavior personalization as a mean to increase entertainment. Before achieving this goal, as previous chapters demonstrate, one must provide the basis of game capabilities. Considering that other phases of design are completed and the game is able to provide a basic experience, it is then possible to study how to effectively tailor the behavior of the robot to the individual human player so as to present an engaging interaction in terms of an appropriate game difficulty. This can be achieved by the modulation of the robot's ability to play considering the existence of a set of discrete styles each one of which presenting its own difficulty. Those styles can be viewed as difficulty settings from which an appropriated one is selected to the player at hand. This is the main idea in strategies for~\glsdesc{dda}, where game designers define approaches to select which game difficulty (\eg, easy, medium, hard) are ideal. 

In our game, the only way to control difficulty is to change properties in the robot behavior, such as speed, and, thus, the difficulty perception is affected only by the modulation of its properties. It is possible that, in other~\gls{pirg}, other elements external to the robot affects the difficulty perception, making an appropriate difficulty selection for the game more complex. Such types of~\gls{pirg}s are outside of our research scope, but the insights we provide can be extended to such cases. 

Specially, in our approach, the effective game difficulty encountered by players is estimated using latent skill representation through the definition of a similarity space. Encoding players and difficulty parameters into such space allows for adaptation, by turning the problem into a recommendation one. Driving the difficulty towards an appropriated level is extensively reported in the literature as responsible for impacting player satisfaction and fun. We also provide observations for robogame designers via the analysis of a theoretical ``risk-ability'' space. This chapter begins with the problem definition.

\section{Problem definition}
We want to exploit past interaction in order to select an ideal robot behavior to be used against the user at hand, thus, hopefully increasing his entertainment. The selected behavior is intended to be one maximizing the entropy of a distribution representing the probability of victory for the player. For this probability mass function, which can be thought of as a Bernoulli distribution, the probability $\rho$ indicates the chances of victory for the player and, conversely, $1-\rho$ indicates the ones for the robot. We hypothesize that the entropy of such binary distribution can be used as a criteria for the task of selecting a balanced behavior, and that occurs when we are not sure which sides are expected to win. In other words, when the entropy is high.

In the process of selecting the appropriated behavior, we assume the game designer has defined a number $|\mathcal{S}|$ of distinct robot parameters which the system can choose from. These parameters are supposed to be related to the game difficulty so as to allow some control over it. In particular, we assume the designer has divided the range of each parameter values into meaningful discrete values, such that it is possible to obtain a finite set of difficulty-related parameters, henceforth called~\gls{ds}. For instance, in RoboTower 2.0, a parameter related to the difficulty of the game is velocity of the robot, which can be used to control the amount of physical activity the human player will engage against. Another parameter is the blocking factor, which essentially defines the tolerance of the robot when competing for a tower. A joint assignment of such variables makes up for a~\gls{ds}. 

One perspective for solving the problem is to take advantage from parametric modeling ideas regarding latent skill modeling. In special, we tackle the problem from the perspective of jointly modeling players and difficulty parameters into a latent space such that it makes it easy to search for balanced settings. This characteristics make our methodology bear some similarity with recommender systems where the item being recommended, in this case, is a game level configuration such that the estimated fun is maximized. 

This way of posing the problem,\ie by having discrete behaviors and appealing for some mechanism for selecting them, had been proposed before in the work of~\cite{sejrsgaard-jacobsen_dynamic_2011}, and can be motivated by the fact that we can separate behavior definition from adaptation. This can also favor other aspects system development, like modularity and maintenance.

Formally, for a player $p$ and a set of~\gls{ds} $\{\mathcal{S}\}^{s=|S|}_{s=1}$ we aim at choosing a setting $s^{\star}$ such that:

\begin{equation}
s^{\star} = \argmax_{s \in \mathcal{S}} \mathcal{G}(s,p, \varphi(p))
\end{equation}
, where $\mathcal{G}$ represents the game and $s^{\star}$ the best game~\gls{ds} $s$ according to a given measure function, $\varphi(p)$. In the next section we discuss our proposal to solve for $s^{\star}$.

\section{Quantifying difficulty}\label{sec:quant_difficulty}
The notion of difficulty is related to several variables. To the extend of a game, it is mostly related to factors like: game controllability, motor coordination, cognitive load management, memory, reasoning, and several others. Although difficulty in itself accounts for all such aspects at once, one usually considers a particular subset of variables under his control and try to understand up to which point their correlation may alter the perceived entertainment.

Following this, we investigate the relation between the dimensions of \textit{progress} and \textit{effort}. The former relates to the quantification of the amount of game progress a given player is likely to have when facing a given difficulty level. This is usually measured in relation with the game score, the state evaluation (as standard practice in games like chess), or even statistics from previous plays. Effort, in turn, relates to the amount of ``resource expenditure'' put by the player as, for example, the cognitive effort, the number of actions taken, the number of in-game resources wasted, etc. In other words, it is designed to quantify the amount of energy spent when playing.

We consider the relationship between effort and progress as providing enough information to support the selection of an appropriate level of play. One obstacle, however, is in the fact that effort does not generally offers a linear relationship with perceived difficulty and it is not straightforward to assume that difficulty is inversely proportional to it,~\ie, it is not always true that a higher resource investment means less ability to play. 
Nonetheless, it is reasonable to assume that players do not conscientiously obtain more entertainment, or advantage, by allocating unnecessary efforts. Following such assumption, one may view a skilled player as one that is constantly trying to minimize energy expenditure while maximizing progress, which supports the hypothesis that players are reasonably classified by considering their progress and effort.

\section{A proposed model: Collaborative effort regression}

Among the most successful techniques for recommender system is~\gls{cl}. This technique is able to make automatic predictions about the interests of a user by collecting preferences from many others. The underlying assumption of the method is that if a user X has the same opinion as a user Y on an issue, X is more likely to have Y's opinion on a different issue than that of a randomly chosen user. Since it glean information from many users exploiting their similarities, and from many it differs from the simpler approach of giving an average (non-specific) score for each item of interest for each user.

From the class of~\gls{cl} approaches, one may observe the potential advantage of~\gls{pmf}~\citep{mnih_probabilistic_2008}. This approach was invented as a type of matrix factorization method. Essentially, it models the user's preference matrix (a matrix of scores, votes, etc.) as a product of two lower-rank user and item matrices. Mathematical details regarding the standard~\gls{pmf} is given in appendix~\ref{app:pmf}.

Relative to our scenario of interest, one can conveniently arrange the score data from players in a matrix form, with rows indicating the player and columns the score when playing against a particular~\gls{ds}. The objective is then to estimate a low-rank matrix associated with each user and another low-rank matrix associated with each~\gls{ds} in way to probabilistic model the score matrix. Following the standard approach in~\gls{pmf}, the modeling can be achieved by a linear model with Gaussian observation noise. 

The~\gls{pmf} model, in its standard form, cannot incorporate the role of effort and the quantification of difficulty discussed in section~\ref{sec:quant_difficulty}. One alternative to this issue is to reuse the~\gls{lda} model from chapter~\ref{ch:modeling} in order to account for different types of effort. The mixture proportions learned in this model, which categorize a player as a combination of effort types uncovered from the data, can be used to represent players and be combined with the latent variables for the~\gls{ds} in the generative process of the score matrix.

It turns out a model of such type was proposed in~\cite{wang_collaborative_2011} and was named as~\gls{ctr}. It combines collaborative filtering and topic modeling in order to fit a model that uses the latent topic space to explain both the observed ratings (votes for an item) and the observed words from the item descriptions. 

The~\gls{ctr} represents users with topic interests and assumes that item description are generated by a topic model. The model additionally includes a latent variable that offsets the topic proportions when modeling the user ratings. As more users rates are available, the more the offset becomes important in explaining preference nuances.

Below we present the derivation of important variables of this model in our domain, here termed~\gls{cer}. Details regarding the general applicability of~\gls{ctr} can be viewed in~\cite{wang_collaborative_2011}.

%I will put the math here tomorrow.