\chapter{Exploring Activity Recognition in Robogames}\label{ch:activity}
%ISSUE: "Exploring Activity Recognition in Robogames"
    %ANDY: This title is too general for a chapter. It should be made more specific and fitting the purpose.
On a~\gls{pirg}, one is often interested in modeling the human player behavior and, from such modeling, program the system to respond properly. Our research began by exploring activity recognition and how it could be incorporated in the design of~\gls{pirg}s. 

In literature, some approaches for activity recognition are based on the analysis of data coming from camera devices. Others, instead, focus on data coming from wearable devices, such as: cellphones, watches and~\gls{imu} -- a specific-purpose device for measuring accelerations and rotation angles. Across years, the type of analysis carried out has pretty much shifted from basic exploratory analysis,~\eg summary statistics %ANDY summary? EWERTON: Summary statistics is a well-known concept, see this: https://en.wikipedia.org/wiki/Summary_statistics
, to complex data-based models, such as those from the~\gls{ml} community. The advantage of this is in the fact that~\gls{ml} models often grant better results due to the identification of hidden structures present in data.

One may spot at least two groups into which to classify works in the area: those performed off-line and those performed on-line. The first focus on the exploitation of methods for the case were data are first collected, tagged and them processed. The philosophy behind on-line methods, as the name suggests, rely on methodologies that can process the data on the go, providing real-time information about the estimated activity. In all of the vast literature in this field,~\gls{ml}-based approaches rely on some kind of transformation to the data in order to increase recognition results. %ANDY this type of considerations would be nice in the state-of-art chapter, to frame what is there. Here you may recall and motivate the line that you followed.
%EWERTON: However, notice that the state-of-art is more concerned with PIRG and not the activity recognition.

In the following, we present how we exploit a simple transformation of the input space targeting the creation of a flexible, generic, and well defined framework for activity recognition in a~\gls{pirg} scenario. To the best of our knowledge, our proposal is the first one to incorporate activity recognition on a~\glsdesc{pirg} involving a human and a mobile robot in an adversarial game setting.

\section{Introduction} %ANDY "introduction" "method", "Result", "Discussion", and "conclusion" are chapter names that should be used only once, namely for the big chapters. Section names should be more specific.

Proper measurement and classification of an individual's physical  activity is fundamental to %understand the relationship between physical activity and health %ANDY What health has to do here?
%, but, also, to achieve an enhanced level of interaction between humans and robots. 
model players in~\gls{pirg}, where the objective is the exploitation of both the real world as environment, and of one or more real, physical, autonomous robots as game opponents or companions of human players. Activity recognition plays a fundamental role to adapt the robot strategy to support the player's entertainment during the game.

Here we propose a model which aims at classifying player's activity in a~\gls{pirg} game using a 3-axis custom accelerometer positioned on the player's chest. We define a set of high level activity classes that are automatically classified relying on a supervised machine learning framework. Our methodology consists of transforming the raw input space into one that is able to capture variance of the signal to emphasize the recognition of the target activities. 

We show that we can obtain reasonable results in accuracy by applying a simple transformation. The achieved results are comparable, in terms of accuracy, with sliding window approaches %ANDY what does this mean? Most data analysis is done on sliding windows. what is peculiar here? Maybe the difference w.r.t. this strange category has to be put in evidence
, which makes our method feasible for real applications, but at lower data processing cost. We tested our methodology on activity recognition in a real robogame scenario~(see section~\ref{sec:game_environment}). 

The chapter is organized as follows: we first present some related works about activity recognition and classification; In section~\ref{datacollection} we explain how we collected data, while in section~\ref{activityanalysis} we provide the description of the activity model. The results are finally discussed in section~\ref{discussion}.

\section{Related Works}\label{relatedworks} %ANDY These should be in the state-of-art section. AN alternative might be to split that section into the different chapters where its contents can refer to something that is described in the chapters. This would be nicer, if possible, and would help to frame the thesis in sub-problems, and to give a structure to the whole.

A number of recent studies have investigated activity recognition using one or more accelerometers placed in different parts of the body. In~\cite{ravi_activity_2005}, a well-cited paper in the activity recognition community, the authors have used a triaxial accelerometer worn near the pelvic region in order to classify eight different daily-life activities: \textit{standing}, \textit{walking}, \textit{running}, \textit{climbing up stairs}, \textit{climbing down stairs}, \textit{sit-ups}, \textit{vacuuming}, and \textit{brushing teeth}.

The windows size used had 256 data-points with 128 samples overlapping ($50\%$ overlap) between consecutive windows. At a sampling frequency of 50Hz, each window represents data for 5.12 seconds. This amount of overlap is justified by the work of~\cite{bao_activity_2004}, where they demonstrated the feasibility of such overlap. %ANDY The fact that something is feasible does not tell that it is suitable...so cannot be a justification.

Considering a game environment,~\cite{jablonsky_evaluating_2017} investigated sensor placement and modality for activity recognition within the context of children's playground  activities. By mean of parallel sensing, performed using a set of smart-phones, activity dependent data have been generated. The obtained set of data was then used to train decision tree classifiers. This study shows once again that sensors (included in phones in this case) placed closer to the core of the body generate better models than sensors placed on the  extremities. 

Similarly, in~\cite{alshurafa_designing_2014} a stochastic approximation framework for intensity independent activity recognition based on clustering techniques is proposed. The aim is to enhance and automate the calculation of~\gls{met} and also to improve an exergaming (video games that are also a form of exercise) platform consisting of two main components: an accelerometer-embedded belt and an~\gls{rpg} video game called \textit{FreedroidRPG} that was used as incentive for the participant to perform physical activity throughout the day. The study shows the ability of the used stochastic approximation framework to extrapolate unknown intensity levels from a few known ones that can be used to enhance activity recognition.

Several studies in the literature also focused on the comparison between multi-sensor versus single-sensor activity detection and also on the optimal body placement of such sensors. The work of~\cite{gao_evaluation_2014} compared two distinct types of wearable systems: single-sensor wearable systems adopting complex algorithms and multi-sensor systems that employ lightweight algorithms. The impact of the sampling rate on the recognition accuracy was then investigated using four classifiers. The experimental results illustrated that the recognition accuracy was steady at 50-Hz and above, and the single sensor system was more sensitive to the sampling rate than the multi-sensor system.

The work of~\cite{trost_machine_2014} is, in turn, focused on making a comparison between the activity recognition rates of an activity classifier trained on acceleration signal collected on the wrist and hip. During the experiments 52 children and adolescents completed 12 activity trials that were categorized into 7 activity classes: \textit{lying down}, \textit{sitting}, \textit{standing}, \textit{walking}, \textit{running}, \textit{basketball}, and \textit{dancing}. As result, the hip model exhibited great classification accuracy for \textit{sitting}, \textit{standing}, \textit{walking}, and \textit{running}; acceptable classification accuracy for \textit{lying down} and \textit{basketball}; and modest accuracy for \textit{dance}. The wrist model, in turn, exhibited excellent classification accuracy for \textit{sitting}, \textit{standing}, and \textit{walking}; acceptable classification accuracy for \textit{basketball}; and modest accuracy for \textit{running}, \textit{lying down} and \textit{dance}.

We followed the popular approaches, such as~\cite{ravi_activity_2005} and~\cite{bao_activity_2004}, where the methodology relies on the use of supervised learning methods, powered by the extraction of informative features from a sliding window. However, the use of such method in our application scenario rises same special issues: since the annotated data come from real game interaction between a human and a mobile robot, the activities are not limited in any aspect.

Additionally, when using a traditional sliding window method, special attention has to be made on the choice of window size. This is because while a too narrow window will produce very accurate representations of the current state, the results will also be heavily affected by noise. On the other hand, a too wide window results in more stable, yet similarly inaccurate results due to the effects of change in the underlying data~\citep{bifet_learning_2007}. 

Equally concerning, fixed-size windows are likely to ignore differences in the duration of activities. This happens very often in our scenarios where different in-game situations would make the players react differently. For instance, the time the player spends running is a product of multiple factors, including personal motivations and robot state given in-game situation. This would demand adaptive strategies for using sliding windows, as suggested by~\cite{noor_adaptive_2016}. However, in this work we follow a different route, by proposing to perform activity recognition by first transforming the data stream input space (acceleration raw data) into a different space that would capture the ``turbulence'' of the signal underlying each activity of interest. The motivation is that a running activity, for example, would be categorized by a different amount of turbulence compared to other activities.

\subsection{Data Collection}\label{datacollection}

%When playing the game (see section~\ref{sec:game_environment}), we ask the human player to wear a colored robe (see figure~\ref{game}) in order to allow for blob detection and tracking, leading to feature extraction. These visual features, however, were out of the scope of this experiment, since we describe only results relying on the accelerometer data. %ANDY So lets' trim this sentence
To detect player movement, we have used a custom accelerometer board attached to the player's chest in order to capture detailed player motion information. The device is based on the InvenSense MPU-6050 3-axis accelerometer board and an Arduino Uno micro-controller. The circuit also contains a Nrf24l01 radio-frequency module that allows the accelerometer data to be sent to the on-board computer. Figure~\ref{fig:the_accelerometer} shows our custom accelerometer device.

\begin{figure}[H]
      \centering
      \begin{subfigure}[t]{0.5\textwidth}
      	\centering
	    \includegraphics[width=5cm,height=3cm]{images/04-activity/sender.jpg}
	    \caption{}
	  \end{subfigure}
	  ~
	  \begin{subfigure}[t]{0.5\textwidth}
      	\centering
	    \includegraphics[width=5cm,height=3cm]{images/04-activity/receiver.jpg}
	    \caption{}
	  \end{subfigure}
      \caption{a) the accelerometer transmitter circuit and b) the receiver circuit used onboard. Both circuit are based on Arduino boards.}\label{fig:the_accelerometer}
\end{figure}

The choice of the accelerometer position was conditioned by the need to minimize the influence of noise due to irrelevant player motion.

\begin{figure}[thpb]
      \centering
      {\includegraphics[width=8cm]{images/04-activity/event.jpg}}
      \caption{Human player (in magenta) during the game. The playground configuration in this trial consisted of 3 target towers.}
      \label{game}
\end{figure}

For example, hand-waving when pressing buttons are not supposed to be meaningful to identify player activities, since the full state of towers is transmitted to the robot via wireless communication including the fact that the player is pressing the button. Therefore, having the device placed on the wrist, or other highly movable body-part (as the feet or head) would capture useless acceleration information contributing to a worse in classification accuracy for the mentioned target motions %ANDY These should be defined more precisely: what motons did you expect to capture?
We decided to place the accelerometer on the chest, in order to capture the essential player motion.

In terms of collected data, for this work, we considered 29 matches involving 15 male participants of different ages. The age distribution consisted of children (7-10) and adults (26-40). Matches had a minimum time duration of about 40 seconds and a maximum of about 1 minute and 10 seconds. 

The collected data correspond to acceleration values along x, y, and z axis with a sampling frequency of 50Hz, which is five times higher than the frequency considered to be sufficient for detecting daily activities from accelerometer data (10Hz)~\cite{atallah_sensor_2010, ravi_activity_2005, kikhia_analyzing_2014}.

\begin{figure*}[!t]
\normalsize
      \centering
      {\includegraphics[width=\textwidth, height=4cm]{images/04-activity/diagram.png}}
      \caption{Overview of the activity recognition system.}
      \label{approach}
\end{figure*}
  
\section{Method}
\subsection{Activity analysis}\label{activityanalysis}

%ANDY This should be stated in advance, since it provides the goal for this activity and allows to specify it better ->
In our game, by using an accelerometer attached to the player, we were mainly interested on identifying activities that would help to describe the player interaction level. For the scope of this work, we aimed at identifying recurrent physical activities that would be useful for achieving that goal. From the collected data (see section~\ref{datacollection}), we were able to identify a few high-level activity types, listed below:

\begin{itemize}
\item  \textbf{running:} describes a running activity. For this experiment, multiple styles of running are not considered. For instance, ``fast'' or ``slow'' running are considered as the same.
\item \textbf{walking/dodging:} represents the walking and dodging activity. The latter refers to a sudden quick movement to avoid the robot or to call its attention.
\item  \textbf{locally\_moving:} a player generic motion that is too small to fall into other categories, but not so small to be characterized as inactivity. Motion to block to block the path of the robot also fall into this type of motion.
\item  \textbf{inactive:} motion that are too low in intensity to be characterized as one of the above activities. A crisp threshold is used to delimit this category. 
\end{itemize}

By analyzing the data, we observed that player activities occur in ``bursts'' that are followed by a short period of inactivity (or rest), i.e., a short period where the player is not really moving, or the expressed acceleration is too small to be related to any activity of interest.

Resting periods are a common characteristic present in any physical game and is related to the organic human need for resting after an intense physical activity or even during strategic moments of pause. Examples of this can be seen when the player is pushing a button on a tower, or is trying to block the robot's path or even when is waiting still for a specific robot position on the environment.

On such moments of inactivity, the changes in acceleration are usually small, reflected in a relative flatness of the signal (e.g., secs 9-12 and 15-18 on figure~\ref{acc_graph}) and this enables the delimitation of an activity begin/end moment.

\begin{figure}[h!]
      \centering
      \includegraphics[width=\linewidth]{images/04-activity/newGraph.eps}
      \caption{Graph of acceleration in x, y and z axis for a game that lasted about 40 seconds.}
      \label{acc_graph}
\end{figure}

One way to describe the activity information associated to the acceleration patterns is by considering the amount of signal ``turbulence''. As a measure of such turbulence, we rely on the information present on the signal variance. 

For this, we process the incoming data stream by computing the standard deviation of the signal inside a sliding window. This transforms the original input space in a new space where activity information is much more evident, resulting in the generation of a continuous graph, where pulses refer to a given player's physical activity (see figure~\ref{fig:std_graph}). % Also, in my opinion, this analysis is still representative without being affected by the noise coming from the accelerometer's signal so it's feasible also for cheap devices that cannot guarantee a great measurement accuracy. Do you think is the case to say this? %ANDY Yes!

Working in this way turns out to be simpler than to perform data annotation by, for instance, using a predefined sliding windows size. In our case, activities, such as ``running'', do not have fixed time duration, which makes the applicability of fixed sliding windows methods not quite suitable~\cite{noor_adaptive_2016}.

\begin{figure}[H]
      \centering
      \includegraphics[width=\linewidth]{images/04-activity/newStdGraph.eps}
      \caption{Standard deviation of the acceleration in Figure~\ref{acc_graph}, computed using a sliding window of half a second. The red line portions represent variance values inside the inactivity zone (below a threshold of 0.2). Green areas are referenced as ``motion primitives''.}\label{fig:std_graph}
\end{figure}

After performing the mentioned data transformation, we have empirically identified a crisp threshold that would catch irrelevant signal values, thus, we say that any value below that threshold is related to player's inactivity.

The inactivity threshold is game-dependent and sensitive to the position of the accelerometer as well. On our experiments, the selection of the inactivity threshold is done manually, via inspection of video recorded during the game.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
     	\centering
        \includegraphics[width=3cm,height=3cm]{images/04-activity/enricorun.png}
        \caption{}
	\end{subfigure}
	~
    \begin{subfigure}[b]{0.3\textwidth}
     	\centering
        \includegraphics[width=3cm,height=3cm]{images/04-activity/run1.png}
        \caption{}
	\end{subfigure}
	\caption{a) Player performing a running activity;  b) Associated running motion primitive.}\label{fig:running}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
  	 \centering
      \includegraphics[width=3cm,height=3cm]{images/04-activity/enricostill.png}
      \caption{}
  \end{subfigure}
  \begin{subfigure}[b]{0.3\textwidth}
  	 \centering
      \includegraphics[width=3cm,height=3cm]{images/04-activity/still.png}
      \caption{}
  \end{subfigure}
  \caption{a) Player performing local movements; b) Associated motion primitive.}    
  \label{fig:localmov}
\end{figure}
    
Since any motion information below the threshold is used to determine the ``inactivity'' of the player, we use machine learning-based classification only on each data interval above the threshold. This interval is called a ``motion primitive'' (Figure~\ref{fig:std_graph}). The motion primitives are the data aggregations to which we associate a class label in the annotation procedure. 

Following the classification need, we have extracted the following descriptors from the motion primitives (recall: they refer to standard deviation of the raw values): 

\begin{itemize}
\item \textbf{mean}:  the mean values.
\item \textbf{activity\_time}: the time duration in seconds.
\item \textbf{max\_peaks}:  the max peak.
\item \textbf{number\_of\_peaks}:  the number of peaks.
\item \textbf{mean\_of\_peaks}: the mean of all peaks.
\item \textbf{max-min}: difference between max and min.
\item \textbf{std}: standard deviation.
\item \textbf{mad}: median absolute deviation.
\item \textbf{sma}: signal magnitude area.
\item \textbf{energy}: the signal energy.
\item \textbf{iqr}: interquartile range.
\item \textbf{mean\_over\_max}: mean of peaks divided by the max peak.
\item \textbf{maxInd}: index of the frequency component with largest magnitude.
\item \textbf{meanFreq}:  weighted average of the frequency components to obtain a mean frequency.
\item \textbf{skewness}:  skewness of the motion primitive.
\item \textbf{kurtosis}:  kurtosis of the motion primitive.
\item \textbf{freq-skewness}: skewness of the frequency domain signal.
\item \textbf{freq-kurtosis}: kurtosis of the frequency domain signal.
\item \textbf{pse}: Power spectral entropy.
\item \textbf{rms}: Return the root mean square.
\end{itemize}

%\begin{figure*}[!t]
% ensure that we have normalsize text
%\normalsize
%      \centering
%      {\includegraphics[width=\textwidth]{figures/featureImportance.eps}}
%      \caption{Feature importance computed by a forest of decision trees classifiers.}
%      \label{feature_importance}
%\end{figure*}

Note that the motion primitives carry sufficient information to distinguish between target physical activities. For example, ``running'' is related to a motion primitive that has a longer duration and a higher amplitude value (see figure~\ref{fig:running}) as opposed to the duration and amplitude values of a player local motion (figure~\ref{fig:localmov}). Following the same argument, a ``walking'' activity has higher amplitude values compared with a local movement. A holistic view of the classification approach is detailed in Figure~\ref{approach}. 

\subsection{Classification setup}

For the automatic classification, we first build the standard deviation graph from the raw accelerometer data, and then we manually label motion primitives. 

On our experiments, the std graph was generated considering a sliding window 500msec long %ANDY If you report the windows length here you should also report the overlapping
, resulting on a dataset composed by $367$ motion primitives. Empirically, this time length turned out to be descriptive enough to produce variance intervals that made it possible to distinguish activities. Naturally, the windows size has an impact on the total number of motion primitives generated per game match, as well as on the inactive threshold value. With a windows size of half a second, however, it was possible to capture immediate transition between activities, given that such transition would manifest on higher spikes on variance at the beginning of an activity. For this reason, we kept the mentioned size. 

The primitives were labeled as follows: $34\%$ as ``locally\_moving''; $25\%$ as ``walking/dodging'' and $41\%$ as ``running''.%ANDY and the others? would say a reader, these do not sum to 100% Are the others teh "inactive"? This should be mentioned here.
As argued above, the ``inactive'' type had not to be labeled, since it is directly classified by the inactive threshold. From video log inspection, we observed that most of the useless motion would occur below a threshold of $0.2$.

Before training classifiers, we performed feature selection by evaluating the importance of the extracted features (see section~\ref{activityanalysis}) using random forest method, composed by 300 decision trees.% (see Figure~\ref{feature_importance}).

\section{Results and discussion}\label{discussion}

We tested different classifiers using 10-fold cross validation in order to have a more descriptive accuracy information. Following common practice, the train-test dataset ratio was defined as 80\% and 20\% respectively.

\begin{table}[h]\footnotesize
  \centering
  \caption{Cross-validation accuracy results for several classification methods using the 5 most significant features.% show in Figure~\ref{feature_importance}.
  }
  \begin{tabular}{| c | c |}
    \hline
  	   \textbf{Method}          & \textbf{Accuracy}\\\hline
       SVM (Linear Kernel)      & 0.80 (+/- 0.08)  \\\hline
       Random Forest            & 0.81 (+/- 0.06)  \\\hline
       Gaussian Naive Bayes     & 0.80 (+/- 0.11)  \\\hline
       Ensemble (Hard voting)   & 0.82 (+/- 0.10)  \\\hline
       AdaBoost                 & 0.65 (+/- 0.40)   \\\hline
  \end{tabular}
  \label{accuracy5best}
\end{table}


Table~\ref{accuracy5best} presents 10-fold cross validation results using different classifiers on the five most important features, that is: \textit{rms}, \textit{fft\_energy}, \textit{sma}, \textit{max\_peak} and \textit{mean}. 

The ensemble reported in Table~\ref{accuracy5best} is defined as a majority (Hard) voting approach by the combination of the SVM, Gaussian Naive Bayes and Random Forest. The Adaboost method, in turn, takes a combination of 100 weak classifiers (Decision Trees). All methods were trained by using Python Scikit-learn machine learning library.

Despite the effort, with a confidence interval of 95\% we see that SVM, Random Forest, Gaussian Naive Bayes as well as their ensemble have a similar accuracy result. By considering the variance in their result, we see that Random Forest gives the most stable result. 

\begin{table}[h]\footnotesize
  \centering
  \caption{Classification report for the chosen ensemble method (Random Forest) %ANDY The terms used in the table have to be defined here (f1-score, LM, WD, R)
  }
  \begin{tabular}{| c | c | c | c | c |}
    \hline
  	   & precision   & recall & f1-score &  support \\\hline
    LM &      0.88   &  0.91  &    0.89  &      23  \\\hline
    WD &      0.79   &  0.60 &     0.68 &       25  \\\hline
     R &      0.77   &  0.92 &     0.84 &       26  \\\hline
avg/total &   0.81   &  0.81 &     0.80 &       74  \\\hline
  \end{tabular}
  \label{report}
\end{table}

Given the 10-fold cross validation results, we decided to use as final method the Random Forest ensemble classifier (10 decision trees). Detailed results for the method are shown in table~\ref{report} and the corresponding confusion matrix and~\gls{roc} in Figure~\ref{fig:mtx-roc}. The majority of mistakes in the classification correspond to the difficulty in separating ``walking/dodging'' from  a ``running'' activity. 

The justification for this may be on the fact that occasionally the player walks in a fast way, which is similar to proper running. This is acceptable given that even for humans it is not straightforward to decide about the boundary conditions of two different, but related activities.

Despite the fact that our method relies on the computation of a fixed slide window when transforming the input data, we see that our method also allows for a small improvement in the annotation procedure. Consider, for example, that we do not have to worry about the effects of overlapping windows. Things like the choice of windowing functions, which are used to mitigate the effects of overlap, are not needed. Also, it allows for a more intuitive way of perceiving what underlying activity has occurred.

We have conducted experiments on using our method online, and the results have been satisfactory. One drawback, however, is on the possibility of having two different activities associated to the same motion primitive. This is likely to occur when the player rapidly shifts between two activities. For example, this happens when the player stops running for a fraction of a second and then immediately starts walking. In that case we see a small decrease in the signal variance that may not be enough to characterize an inactivity period. Note that a value below the inactive threshold is the event that separates motion primitives.

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{7cm}
       \centering
       \includegraphics[width=7cm, height=5cm]{images/04-activity/conf_mtx.eps}
       \caption{}
	\end{subfigure}
	~
    \begin{subfigure}[b]{7cm}
     	\centering
        \includegraphics[width=7cm, height=6cm]{images/04-activity/roc.eps}
        \caption{}
	\end{subfigure}
	\caption{a) Confusion matrix for the trained Random Forest ensemble method and the associated. b) \gls{roc} curve.}\label{fig:mtx-roc}
\end{figure}

\section{Considerations}
% reviewers said that the paper lacks of novelty. Maybe in the conclusion we should point out again that our methods is designed to be as more general as possible (we don't rely on pre-defined activities, the player is free to move as he want, it works for individuals with very different phisical building etc...). Also some comparison between our results and the one of other studies should be made, I think we should point on the generality of the solution. In general in the conclusion section we should answer to the question "why should I use this method instead of another one???" any idea?? - DAVIDE%
%IDEA 1 - our methods is quite easy to be implemented and does not require a big computational effort, besides in its simplicity is also a powerful and intuitive description method for both type and level of activity with a good level of accuracy (something like this) - DAVIDE%
In this work, we have investigated the recognition of high-level human player activity in a Physically Interactive RobotGame (PIRG) scenario, where a human player faces a mobile robot. We have used the variance in player motion as data instances and primary source of information from where to extract features and then train a machine learning model. 

Physically Interactive RoboGames are a rather new style of game and provide a specific setting from which to study human-robot interaction in situations framed by rules.

In order to design better PIRGs where, for instance, robots can adapt their strategies to support the player entertainment, a player activity model is desired, for which activity recognition is fundamental. 

%ANDY This should have been done and had been a strong point -> We are currently working on the real-time applicability of this method as for the support of methodologies that are capable of quantifying the player engagement by, for instance, analyzing the rate of change in the number of activities performed by the player during the game.

%ANDY At this point, if we like toinclude this chapter, we should say why we abandoned accelerometers... and find a good motivation, e.g. because we can obtain the same information from lasers, with same or better quality without using accelerometers.
