{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### \n",
    "# Created by Ewerton Lopes\n",
    "# Politecnico di Milano, December, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from pandas.tools.plotting import lag_plot, autocorrelation_plot\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "import scipy.fftpack as fft\n",
    "from helper_functions import getListOfFiles, getCSV, getStatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** </br>\n",
    "1. Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features selected for this dataset come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. That signal was taken using the <a href=http://playground.arduino.cc/Main/MPU-6050> InvenSense MPU-6050 </a> sensor, which contains a MEMS accelerometer and a MEMS gyro in a single chip. The sensor possess a 16-bits analog to digital conversion hardware for each channel. Therefor it captures the x, y, and z channel at the same time. The sensor was used with the I2C-bus to interface with an Arduino attached to the player.  We also use a Microsoft Kinect 2 sensor in order to get 3 additional features: Contraction Index (CI), distance, proximity. This last feature is a normalized - [0,1] interval - version of distance. Thus, they shall be used in mutually exclusion. The normalization is done by limiting the distance to 4.5 meters, the known stable limit of the sensor. So, the player has a greater proximity value when it is seen close to the robot. The value tends to zero otherwise. Ideally, the CI feature correspond to how open-wide (in terms of legs and arms) the player is.\n",
    "\n",
    "Here, we organize the feature similar to <a href=https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones> Anguita at al.</a>. The time domain signals are (prefix 't' to denote time) were captured at a about rate of 48 Hz for the MPU-6050 based data. <font color='red'>Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz.\n",
    "\n",
    "Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals\n",
    "(tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated\n",
    "using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag).\n",
    "\n",
    "Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ,\n",
    "fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag.\n",
    "(Note the 'f' to indicate frequency domain signals).\n",
    "\n",
    "These signals were used to estimate variables of the feature vector for each pattern:  \n",
    "'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.\n",
    "\n",
    "tBodyAcc-XYZ\n",
    "tGravityAcc-XYZ\n",
    "tBodyAccJerk-XYZ\n",
    "tBodyGyro-XYZ\n",
    "tBodyGyroJerk-XYZ\n",
    "tBodyAccMag\n",
    "tGravityAccMag\n",
    "tBodyAccJerkMag\n",
    "tBodyGyroMag\n",
    "tBodyGyroJerkMag\n",
    "fBodyAcc-XYZ\n",
    "fBodyAccJerk-XYZ\n",
    "fBodyGyro-XYZ\n",
    "fBodyAccMag\n",
    "fBodyAccJerkMag\n",
    "fBodyGyroMag\n",
    "fBodyGyroJerkMag\n",
    "\n",
    "The set of variables that were estimated from these signals are: \n",
    "\n",
    "mean(): Mean value\n",
    "std(): Standard deviation\n",
    "mad(): Median absolute deviation \n",
    "max(): Largest value in array\n",
    "min(): Smallest value in array\n",
    "sma(): Signal magnitude area\n",
    "energy(): Energy measure. Sum of the squares divided by the number of values. \n",
    "iqr(): Interquartile range \n",
    "entropy(): Signal entropy\n",
    "arCoeff(): Autorregresion coefficients with Burg order equal to 4\n",
    "correlation(): correlation coefficient between two signals\n",
    "maxInds(): index of the frequency component with largest magnitude\n",
    "meanFreq(): Weighted average of the frequency components to obtain a mean frequency\n",
    "skewness(): skewness of the frequency domain signal \n",
    "kurtosis(): kurtosis of the frequency domain signal \n",
    "bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.\n",
    "angle(): Angle between to vectors.\n",
    "\n",
    "Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:\n",
    "\n",
    "gravityMean\n",
    "tBodyAccMean\n",
    "tBodyAccJerkMean\n",
    "tBodyGyroMean\n",
    "tBodyGyroJerkMean\n",
    "\n",
    "The complete list of variables of each feature vector is available in 'features.txt' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the csv files, that together comprise the our dataset, from the `.data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 34 CSV Files found:\n",
      "\n",
      "[\"_2016-11-23-18-49-13_exp1_Player.csv\", \"_2016-11-23-18-49-13_exp2_Player.csv\", \"_2016-11-23-18-49-13_exp3_Player.csv\", \"_2016-11-23-18-49-13_exp4_Player.csv\", \"_2016-11-23-18-49-13_exp5_Player.csv\", \"_2016-11-24-15-43-37_exp1d_Player.csv\", \"_2016-11-24-15-43-37_exp2d_Player.csv\", \"_2016-11-24-15-43-37_exp3d_Player.csv\", \"_2016-11-24-15-43-37_exp4d_Player.csv\", \"_2016-11-24-15-43-37_exp5d_Player.csv\", \"_2016-11-24-15-43-37_exp6d_Player.csv\", \"_2016-11-24-16-23-29_expa_Player.csv\", \"_2016-11-24-16-23-29_expb_Player.csv\", \"_2016-11-24-16-23-29_expc_Player.csv\", \"_2016-11-24-16-23-29_expd_Player.csv\", \"_2016-11-24-16-48-48_exp1d_Player.csv\", \"_2016-11-24-16-48-48_exp2d_Player.csv\", \"_2016-11-24-16-48-48_exp3d_Player.csv\", \"_2016-11-24-17-15-38_expa_Player.csv\", \"_2016-11-24-17-15-38_expb_Player.csv\", \"_2016-11-24-17-15-38_expc_Player.csv\", \"_2016-11-24-17-40-06_expb_Player.csv\", \"_2016-11-26-15-42-51_exp1d_Player.csv\", \"_2016-11-26-16-05-47_exp1d_Player.csv\", \"_2016-11-26-16-35-21_exp1d_Player.csv\", \"_2016-11-26-16-49-44_exp1d_Player.csv\", \"_2016-11-26-17-15-53_exp2_Player.csv\", \"_2016-11-26-17-15-53_exp3_Player.csv\", \"_2016-11-26-17-15-53_exp4_Player.csv\", \"_2016-11-26-17-15-53_fixed_exp1d_Player.csv\", \"_2016-11-26-17-15-53_fixed_exp2d_Player.csv\", \"_2016-11-26-17-38-21_fixed_exp1d_Player.csv\", \"_2016-11-26-18-36-15_expa_Player.csv\", \"_2016-11-26-18-36-15_expb_Player.csv\"]\n"
     ]
    }
   ],
   "source": [
    "csv_dir = \"./data\"\n",
    "files = getListOfFiles(csv_dir, \".csv\")\n",
    "print \">> {} CSV Files found:\\n\".format(len(files))\n",
    "print json.dumps(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get details about the data stored on the csv files.\n",
    "%run data_summary.py -f data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pdf(data,suptitle=\"PDF fitting\", headers=\"\", normalize_data=False):\n",
    "    \"\"\"Plot the probability density function.\n",
    "    Args:\n",
    "        data (list: pd.Series): the list of data to be used.\n",
    "        headers (list: str)   : list of titles for the plots\n",
    "        normalize_data : normalize data prior to fit the pdf.\n",
    "    \"\"\"\n",
    "\n",
    "    grid_side_size = int(round(np.sqrt(len(data))))\n",
    "    #fig = plt.figure(figsize=(11,7))\n",
    "    fig, axes = plt.subplots(grid_side_size, grid_side_size, figsize=(18,12))\n",
    "    \n",
    "    count = 0\n",
    "    for i, row in enumerate(axes):\n",
    "        for j in range(grid_side_size):\n",
    "            if count >= len(data):\n",
    "                break\n",
    "                \n",
    "            #normalize vector\n",
    "            if normalize_data:\n",
    "                n_data = data[count]/data[count].sum()\n",
    "            else:\n",
    "                n_data = data[count]\n",
    "                \n",
    "            # Fit a normal distribution to the data:\n",
    "            mu, sigma = norm.fit(n_data)\n",
    "            \n",
    "            if headers == \"\":\n",
    "                row[j].set_title(\"{}-Fit. mu={:.2f},  std={:.2f}\".format(count, mu, sigma), fontsize=8)\n",
    "            else:\n",
    "                row[j].set_title(\"Fit for {}. mu={:.2f},  std={:.2f}\".format(headers[count], mu, sigma), fontsize=8)\n",
    "            \n",
    "            # Using the  Freedman-Diaconis rule for getting the number of bins\n",
    "            bin_size = 2 * iqr(n_data) * len(n_data) ** (-1 / 3)\n",
    "            bins = int(round((max(n_data) - min(n_data)) / bin_size))\n",
    "\n",
    "            # Plot the histogram.\n",
    "            bin_value, bin_edges, p = row[j].hist(n_data, bins=bins, normed=True, alpha=0.6, color='g')\n",
    "            \n",
    "            # Normalizing heights\n",
    "            #debug = 0\n",
    "            #for i, item in enumerate(p):\n",
    "            #    debug += (bin_value[i] / sum(bin_value*np.diff(bin_edges)))\n",
    "            #    item.set = bin_value[i]/ sum(bin_value*np.diff(bin_edges))\n",
    "            #print debug\n",
    "\n",
    "            # Plot the PDF.\n",
    "            xmin, xmax = row[j].get_xlim()\n",
    "            x = np.linspace(xmin, xmax, 100)\n",
    "            p = norm.pdf(x, mu, sigma)\n",
    "            row[j].plot(x, p, 'k', linewidth=2, color='r')\n",
    "            count += 1\n",
    "\n",
    "    fig.suptitle(suptitle, fontsize=21)\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    plt.draw()\n",
    "\n",
    "def gridOfPlots(data, columnToPlot, suptitle=\"PDF fitting\"):\n",
    "    \"\"\"Plots the data in a grid of plots.\n",
    "    Args:\n",
    "        data (list): the list of data to be used.\n",
    "        title (str): grid title.\n",
    "        columnToPlot: the column in the data to be plotted.\n",
    "    \"\"\"\n",
    "    \n",
    "    grid_side_size = int(round(np.sqrt(len(data))))\n",
    "    fig, axes = plt.subplots(grid_side_size, grid_side_size, figsize=(18,12))\n",
    "\n",
    "    count = 0\n",
    "    for i, row in enumerate(axes):\n",
    "        for j in range(grid_side_size):\n",
    "            if count >= len(data):\n",
    "                break\n",
    "            row[j].set_title(\"Windows-{}\".format(count), fontsize=8, fontweight=\"bold\")\n",
    "            row[j].plot(data[count][columnToPlot].dropna())\n",
    "            count += 1\n",
    "\n",
    "    fig.suptitle(suptitle, fontsize=21)\n",
    "    fig.subplots_adjust(hspace=0.5, wspace= 0.4)\n",
    "    plt.draw()\n",
    "\n",
    "def gridOfLagPlots(data, columnToPlot, suptitle=\"Plot\"):\n",
    "    \"\"\"Plots a grid of plots corresponding to a lag-one time series \n",
    "    graph for the given column.\n",
    "    \n",
    "    The 'abscissa' correspond to the column value at time t. The 'ordinate' correspond\n",
    "    to the column value at time t-1. Hence the name 'lag-one' time series plot.\n",
    "    \n",
    "    Args:\n",
    "        data (list): the list of data to be used.\n",
    "        title (str): grid title.\n",
    "        columnToPlot: the column in the data to be plotted.\n",
    "    \"\"\"\n",
    "    grid_side_size = int(round(np.sqrt(len(data))))\n",
    "    plt.figure(figsize=(18,12))\n",
    "\n",
    "    count = 0\n",
    "    for i in range(grid_side_size):\n",
    "        for j in range(grid_side_size):\n",
    "            if count >= len(data):\n",
    "                break\n",
    "            plt.subplot(grid_side_size,grid_side_size,count+1)\n",
    "            lag_plot(data[count][columnToPlot].dropna())\n",
    "            plt.title(\"Windows-{}\".format(count))\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    plt.suptitle(suptitle, fontsize=21)\n",
    "    plt.subplots_adjust(hspace=0.5, wspace= 0.4)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a dictionary containing a remap of the name of the features. This is to easy visualization since ros feature names may be very long and also allow quick decoupled modifications (just edit the variable locally). Also, from it we define a ignore list containing the names we do not want to consider for the analysis. That is done by setting to the ignore list all dictionary keys with empty values. **Here we assume the names are consistent feature name w.r.t. the `csv` data. Otherwise, a `ValueError` exception is likely to be thrown!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of ignored topics: []\n"
     ]
    }
   ],
   "source": [
    "# variable for storing the loaded feature names.\n",
    "feature_name_map = {\n",
    "  \"time\" : \"time\",\n",
    "  \"Control\": \"control\",\n",
    "  \"High_level\": \"high_level\",\n",
    "  \"Expectation\": \"expectation\",\n",
    "  \"Activity\": \"activity\",\n",
    "  \"/kinect_features/.ci\": \"ci\",\n",
    "  \"/kinect_features/.distance\": \"distance\",\n",
    "  \"/kinect_features/.proximity\": \"proximity\",\n",
    "  \"robogame/imu_state.gyro.x\": \"gyroX\",\n",
    "  \"robogame/imu_state.gyro.y\": \"gyroY\",\n",
    "  \"robogame/imu_state.gyro.z\": \"gyroZ\",\n",
    "  \"robogame/imu_state.linear_acc.x\": \"accX\",\n",
    "  \"robogame/imu_state.linear_acc.y\": \"accY\",\n",
    "  \"robogame/imu_state.linear_acc.z\": \"accZ\"\n",
    "}\n",
    "\n",
    "ignore_col_list = [k for k,v in feature_name_map.items() if v is \"\"]\n",
    "print \"List of ignored topics: {}\".format(ignore_col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin the analysis using only one file. Of course, once it is completed, we extend the analysis for the other files in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: \"_2016-11-23-18-49-13_exp1_Player.csv\"\n",
      "Retrieved 24 windows in _2016-11-23-18-49-13_exp1_Player.csv\n",
      "LOAD SUMMARY:\n",
      "  #Win    Avg. Overlap    Avg. dev. from ref.\n",
      "------  --------------  ---------------------\n",
      "    24           49.99                  -0.01\n"
     ]
    }
   ],
   "source": [
    "csv_filename = files[0]  # get only the fist loaded csv file.\n",
    "csv_data = None          # the variable where the loaded csv data is stored.\n",
    "num_windows = 0          # the number of windows loaded.\n",
    "wFrames = []             # the list of windows data. Each element is a pandas dataframe \n",
    "                         #  corresponding to the windows. The list is of size 'num_windows'.\n",
    "\n",
    "print 'Processing: \"{}\"'.format(csv_filename)\n",
    "\n",
    "# load the data, abort in case of error.\n",
    "try:\n",
    "    num_windows, csv_data = getCSV(os.path.join(csv_dir, csv_filename))\n",
    "except ValueError as e:\n",
    "    print traceback.format_exc()\n",
    "    sys.exit(-1)\n",
    "\n",
    "for w in range(num_windows):\n",
    "    win_data = {}\n",
    "    for k in csv_data.keys():\n",
    "        # consider the data only if it is not in the ignore list.\n",
    "        if k not in ignore_col_list:\n",
    "            win_data[feature_name_map[k]] = csv_data[k][w]\n",
    "\n",
    "    # convert dictionary to dataframe and save it to list of all windows data for the file.\n",
    "    wFrames.append(pd.DataFrame.from_dict(win_data))\n",
    "print 'Retrieved {} windows in {}'.format(num_windows, csv_filename)\n",
    "overlap_reference = 50\n",
    "_, n_windows, sample_info, avg_overlap, avg_diff = getStatistics(csv_data, compareWith=overlap_reference)\n",
    "\n",
    "print \"LOAD SUMMARY:\"\n",
    "print tabulate([[n_windows,\"{:.2f}\".format(avg_overlap),\"{:.2f}\".format(avg_diff)]],\n",
    "                   headers=[\"#Win\", \"Avg. Overlap\", \"Avg. dev. from ref.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the accelerometer signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gridOfPlots(wFrames, suptitle=\"Accelerometer data X axis\", columnToPlot=\"accX\")\n",
    "gridOfPlots(wFrames, suptitle=\"Accelerometer data Y axis\", columnToPlot=\"accY\")\n",
    "gridOfPlots(wFrames, suptitle=\"Accelerometer data Z axis\", columnToPlot=\"accZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a PDF on the accelerometer and gyroscope data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdf([w[\"accX\"].dropna().as_matrix() for w in wFrames], suptitle=\"AccX\")\n",
    "pdf([w[\"accY\"].dropna().as_matrix() for w in wFrames], suptitle=\"AccY\")\n",
    "pdf([w[\"accZ\"].dropna().as_matrix() for w in wFrames], suptitle=\"AccZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pdf([w[\"gyroX\"].dropna().as_matrix() for w in wFrames], suptitle=\"gyroX\")\n",
    "pdf([w[\"gyroY\"].dropna().as_matrix() for w in wFrames], suptitle=\"gyroY\")\n",
    "pdf([w[\"gyroZ\"].dropna().as_matrix() for w in wFrames], suptitle=\"gyroZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Fitting a pdf to the Microsoft Kinect 2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pdf([w[\"ci\"].dropna().as_matrix() for w in wFrames], suptitle=\"ci\")\n",
    "#pdf([w[\"distance\"].dropna().as_matrix() for w in wFrames], suptitle=\"distance\")\n",
    "#pdf([w[\"proximity\"].dropna().as_matrix() for w in wFrames], suptitle=\"proximity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting One-lag time graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - accX\", columnToPlot=\"accX\")\n",
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - accY\", columnToPlot=\"accY\")\n",
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - accZ\", columnToPlot=\"accZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - gyroX\", columnToPlot=\"gyroX\")\n",
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - gyroY\", columnToPlot=\"gyroY\")\n",
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - gyroZ\", columnToPlot=\"gyroZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - ci\", columnToPlot=\"ci\")\n",
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - distance\", columnToPlot=\"distance\")\n",
    "gridOfLagPlots(wFrames, suptitle=\"One Lag scatters - proximity\", columnToPlot=\"proximity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train autoregression\n",
    "X = wFrames[0][\"accX\"].dropna().as_matrix()\n",
    "train, test = X[1:len(X) - 7], X[len(X) - 7:]\n",
    "model = AR(train)\n",
    "model_fit = model.fit()\n",
    "print('Lag: %s' % model_fit.k_ar)\n",
    "print('Coefficients: %s' % model_fit.params)\n",
    "# make predictions\n",
    "predictions = model_fit.predict(start=len(train), end=len(train) + len(test) - 1, dynamic=False)\n",
    "for i in range(len(predictions)):\n",
    "    print('predicted=%f, expected=%f' % (predictions[i], test[i]))\n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "# plot results\n",
    "plt.figure(\"AR Model\")\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Fast Fourrier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gridOfFFT(data, N_fft, freq_range=64,title=\"Plot\", columnToPlot = None):\n",
    "    grid_side_size = int(round(np.sqrt(len(data))))\n",
    "    plt.figure(title, figsize=(18,12))\n",
    "\n",
    "    Fs = freq_range\n",
    "\n",
    "    count = 0\n",
    "    for i in range(grid_side_size):\n",
    "        for j in range(grid_side_size):\n",
    "            if count >= len(data):\n",
    "                break\n",
    "            ax = plt.subplot(grid_side_size, grid_side_size, count + 1)\n",
    "            freqsig = fft.fft(data[count][columnToPlot].dropna(), n=N_fft)\n",
    "            freq_axis = np.arange(0, Fs, Fs / N_fft)\n",
    "\n",
    "            ax.plot(freq_axis, np.abs(freqsig), lw=2.0, c='b')\n",
    "            p = plt.Rectangle((Fs/2, 0), Fs/2, ax.get_ylim()[1], facecolor=\"grey\", fill=True, alpha=0.75, hatch=\"/\", zorder=3)\n",
    "            ax.add_patch(p)\n",
    "            ax.set_xlim((ax.get_xlim()[0],Fs))\n",
    "            plt.title(\"FFT - Windows{}\".format(count), fontsize=10)\n",
    "            plt.ylabel('FFT magnitude')\n",
    "            plt.xlabel('Frequency (Hz)')\n",
    "            plt.legend((p,), ('excluded',))\n",
    "            plt.grid()\n",
    "            count += 1\n",
    "\n",
    "    plt.suptitle(title, fontsize=21)\n",
    "    plt.subplots_adjust(hspace=0.8, wspace=0.8)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gridOfFFT(wFrames, 138, title=\"FFT for the accX\", columnToPlot=\"accX\")\n",
    "gridOfFFT(wFrames, 138, title=\"FFT for the accY\", columnToPlot=\"accY\")\n",
    "gridOfFFT(wFrames, 138, title=\"FFT for the accZ\", columnToPlot=\"accZ\")\n",
    "gridOfFFT(wFrames, 138, title=\"FFT for the accZ\", columnToPlot=\"accZ\")\n",
    "gridOfFFT(wFrames, 138, title=\"FFT for the ci\", columnToPlot=\"ci\")\n",
    "gridOfFFT(wFrames, 138, title=\"FFT for the proximity\", columnToPlot=\"proximity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate meta-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-feature function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(data):\n",
    "    \"\"\"Calculates mean of the data\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.mean(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.mean(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "\n",
    "def std(data):\n",
    "    \"\"\"Calculates the standard deviation\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.std(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.std(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "\n",
    "def max_value(data):\n",
    "    \"\"\" Calculates Largest value in array\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.max(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.max(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "def min_value(data):\n",
    "    \"\"\"Calculates smallest value in array\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.min(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.min(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "\n",
    "def mad(data):\n",
    "    \"\"\" Calculates the median absolute deviation\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        l = []\n",
    "        for d in data:\n",
    "            m = {}\n",
    "            for k in data._get_numeric_data():\n",
    "                m[k] = abs(data[k].dropna() - data[k].median())\n",
    "                m[k] = pd.Series(m[k]).median()\n",
    "            l.append(pd.Series(m))\n",
    "        return l\n",
    "    else:\n",
    "        m = {}\n",
    "        for k in data._get_numeric_data():\n",
    "            m[k] = abs(data[k].dropna() - data[k].median())\n",
    "            m[k] = pd.Series(m[k]).median()\n",
    "        return pd.Series(m)\n",
    "\n",
    "\n",
    "def sma(data):\n",
    "    \"\"\"Computes Signal magnitude area.\n",
    "    http://dsp.stackexchange.com/questions/18649/signal-magnitude-area\n",
    "    \"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.sum(axis=0, skipna=True, numeric_only=True) / data.shape[0] for d in data]\n",
    "    else:\n",
    "        return data.sum(axis=0, skipna=True, numeric_only=True) / data.shape[0]\n",
    "\n",
    "\n",
    "def energy(data):\n",
    "    \"\"\"Energy measure. Sum of the squares divided by the number of values.\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.dropna().apply(lambda x: x**2).mean(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.dropna().apply(lambda x: x**2).mean(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "\n",
    "def iqr(data):\n",
    "    \"\"\"Calculates the interquartile range\n",
    "    http://stackoverflow.com/questions/23228244/how-do-you-find-the-iqr-in-numpy\n",
    "    \"\"\"\n",
    "    if isinstance(data,np.ndarray):\n",
    "        return np.subtract(*np.percentile(data, [75, 25]))\n",
    "    else:\n",
    "        v = {}\n",
    "        for k in data._get_numeric_data():\n",
    "            v[k] = np.subtract(*np.percentile(data[k].dropna(), [75, 25]))\n",
    "        return pd.Series(v)\n",
    "\n",
    "def entropy(data):\n",
    "    \"\"\"Signal entropy\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating metafeatures for one single windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "                    META-FEATURES - 1 windows\n",
      "*****************************************************************\n",
      "\n",
      "topics         mean      std    max    min    mad      sma      iqr       energy\n",
      "---------  --------  -------  -----  -----  -----  -------  -------  -----------\n",
      "accX       -1071.07  1946.72   2293  -6422   1610  -852.25  3328.25  3.04852e+06\n",
      "accY         428.97   620.15   2006  -1131  354.5   341.33   717.75       400689\n",
      "accZ        2056.84  1609.09   8636  -3187    701  1636.62   1335.5  1.41526e+07\n",
      "ci             0.42     0.13   0.72   0.23   0.07     0.09     0.14         0.05\n",
      "distance       0.39     0.29   0.68      0   0.13     0.08     0.64         0.31\n",
      "gyroX          3.44    19.75     54    -63   12.5     2.74    26.25          361\n",
      "gyroY          3.13    19.22     43    -49   12.5     2.49    24.25          676\n",
      "gyroZ         -0.71    13.14     32    -43      9    -0.56    17.25         1849\n",
      "proximity      0.91     0.06      1   0.85   0.03      0.2     0.14         0.77\n",
      "time           1.47     0.87   2.99      0   0.75     1.47     1.51            0\n"
     ]
    }
   ],
   "source": [
    "class tabularData():\n",
    "    def __init__(self):\n",
    "        self.rows = defaultdict(list)\n",
    "        self.headers = ['topics']\n",
    "\n",
    "    def store(self,d,func):\n",
    "        for k,v in d.items():\n",
    "            self.rows[k].append(float(\"{:.2f}\".format(v)))\n",
    "        self.headers.append(func)\n",
    "        \n",
    "    def getData(self):\n",
    "        r = []\n",
    "        for k,v in self.rows.items():\n",
    "            r.append([k] + [i for i in v])\n",
    "        return sorted(r)\n",
    "    \n",
    "    def getHeaders(self):\n",
    "        return self.headers\n",
    "\n",
    "data = wFrames[0]._get_numeric_data()\n",
    "\n",
    "table_rows = tabularData()\n",
    "table_rows.store(mean(data).to_dict(), \"mean\")\n",
    "table_rows.store(std(data).to_dict(), \"std\")\n",
    "table_rows.store(max_value(data).to_dict(), \"max\")\n",
    "table_rows.store(min_value(data).to_dict(), \"min\")\n",
    "table_rows.store(mad(data).to_dict(), \"mad\")\n",
    "table_rows.store(sma(data).to_dict(), \"sma\")\n",
    "table_rows.store(iqr(data).to_dict(), \"iqr\")\n",
    "table_rows.store(energy(data).to_dict(), \"energy\")\n",
    "\n",
    "print 65 * '*'\n",
    "print 20*' '+\"META-FEATURES - 1 windows\"\n",
    "print 65 * '*'\n",
    "print    \n",
    "print tabulate(table_rows.getData(), headers=table_rows.getHeaders(), numalign=\"right\")\n",
    "#print \"Mean:\\n{}\".format(mean(wFrames[0]))\n",
    "#print \"Std:\\n{}\".format(std(wFrames[0]))\n",
    "#print \"Max:\\n{}\".format(max_value(wFrames[0]))\n",
    "#print \"Min:\\n{}\".format(min_value(wFrames[0]))\n",
    "#print \"Mad:\\n{}\".format(mad(wFrames[0]))\n",
    "#print \"Sma:\\n{}\".format(sma(wFrames[0]))\n",
    "#print \"Iqr:\\n{}\".format(iqr(wFrames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "4.66666666667\n",
      "col    4.666667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Testing energy feature.\n",
    "t={\"col\": [1,2,3]}\n",
    "test = pd.DataFrame(t)\n",
    "print test\n",
    "\n",
    "print sum(map(lambda x:x**2, t.values()[0]))/len(t.values()[0])\n",
    "print energy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the metafeatures differ on all windows of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_all = []\n",
    "std_all = []\n",
    "max_all = []\n",
    "min_all = []\n",
    "mad_all = []\n",
    "sma_all = []\n",
    "iqr_all = []\n",
    "\n",
    "for w in wFrames:\n",
    "    mean_all.append(mean(w).to_dict())\n",
    "    std_all.append(std(w).to_dict())\n",
    "    max_all.append(max_value(w).to_dict())\n",
    "    min_all.append(min_value(w).to_dict())\n",
    "    mad_all.append(mad(w).to_dict())\n",
    "    sma_all.append(sma(w).to_dict())\n",
    "    iqr_all.append(iqr(w).to_dict())\n",
    "\n",
    "df = pd.DataFrame.from_records([mean_all, std_all, max_all, min_all, mad_all, sma_all, iqr_all])\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
