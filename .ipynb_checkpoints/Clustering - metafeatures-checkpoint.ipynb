{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering each segment using metafeatures in VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import scipy.fftpack as fft\n",
    "from scipy.stats import norm, skew, kurtosis\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from helper_functions import getListOfFiles, getCSV, getStatistics, remap_interval\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetafeatureVector():\n",
    "    \"\"\"Upon call to store, organize the data in \n",
    "    a dictionary. Convenient for using with csv.DictWriter.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.rows = defaultdict(dict)\n",
    "\n",
    "    def store(self,d,func):\n",
    "        \"\"\"Each new value of a function is stored in a list\n",
    "        for the given attibute.\"\"\"\n",
    "        for k,v in d.items():\n",
    "            self.rows[k][func] = float(\"{:.2f}\".format(v))\n",
    "        \n",
    "    def getData(self):\n",
    "        \"\"\"Return dictionary where each key is the atribute\n",
    "        and its value a dictionary containing the metafeatures\n",
    "        calculated\"\"\"\n",
    "        return self.rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_dict(dd, separator='.', prefix=''):\n",
    "    \"\"\"This function collapses a dictionary into a list, by appending\n",
    "    the keys' values to themselves. That is, parents(keys) are joined together\n",
    "    with children (values) by the separator variable.\n",
    "    dd  :   dictionary to be flattened\n",
    "    separator   :   the character used to join values to their keys.\n",
    "    prefix      :   the character used in place of the value.\n",
    "    \"\"\"\n",
    "    return {prefix + separator + k if prefix else k: v\n",
    "            for kk, vv in dd.items()\n",
    "            for k, v in flatten_dict(vv, separator, kk).items()\n",
    "            } if isinstance(dd, dict) else {prefix: dd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_subsequence(seq, subseq):\n",
    "    target = np.dot(subseq, subseq)\n",
    "    candidates = np.where(np.correlate(seq,\n",
    "                                       subseq, mode='valid') == target)[0]\n",
    "    # some of the candidates entries may be false positives, double check\n",
    "    check = candidates[:, np.newaxis] + np.arange(len(subseq))\n",
    "    mask = np.all((np.take(seq, check) == subseq), axis=-1)\n",
    "    return candidates[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-features function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean(data):\n",
    "    \"\"\"Calculates mean of the data\"\"\"\n",
    "    return np.mean(data)\n",
    "\n",
    "def std(data):\n",
    "    \"\"\"Calculates the standard deviation\"\"\"\n",
    "    return np.std(data)\n",
    "\n",
    "\n",
    "def max_value(data):\n",
    "    \"\"\" Calculates Largest value in array\"\"\"\n",
    "    return np.max(data)\n",
    "    \n",
    "def min_value(data):\n",
    "    \"\"\"Calculates smallest value in array\"\"\"\n",
    "    return np.min(data)\n",
    "\n",
    "def mad(data, axis=None):\n",
    "    \"\"\" \n",
    "    Calculates the median absolute deviation: a \"Robust\" version of standard deviation.\n",
    "        Indices variabililty of the sample.\n",
    "        https://en.wikipedia.org/wiki/Median_absolute_deviation \n",
    "    \"\"\"\n",
    "    return np.median(np.absolute(data - np.median(data, axis)), axis)\n",
    "\n",
    "\n",
    "def sma(data):\n",
    "    \"\"\"Computes Signal magnitude area.\n",
    "    http://dsp.stackexchange.com/questions/18649/signal-magnitude-area\n",
    "    \"\"\"\n",
    "    accumulator = np.sum([np.abs(x) for x in data])\n",
    "    return accumulator / float(len(data))\n",
    "\n",
    "\n",
    "def energy(data):\n",
    "    \"\"\"Energy measure. Sum of the squares divided by the number of values.\"\"\"\n",
    "    return np.sum([x**2 for x in data]) / float(len(data))\n",
    "\n",
    "\n",
    "def iqr(data):\n",
    "    \"\"\"Calculates the interquartile range\n",
    "    http://stackoverflow.com/questions/23228244/how-do-you-find-the-iqr-in-numpy\n",
    "    \"\"\"\n",
    "    return np.subtract(*np.percentile(data, [75, 25]))\n",
    "\n",
    "def maxInds(data, n_bins=200):\n",
    "    \"\"\"Returns the index of the frequency component with largest magnitude\"\"\"\n",
    "    \n",
    "    mean_sig = np.ones_like(data)*np.mean(data)\n",
    "    # remove mean of the signal, for better results.\n",
    "    sig = data - mean_sig\n",
    "    freqsig = fft.fft(sig,n=n_bins) \n",
    "    half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "    #get max index in the freq domain\n",
    "    return np.where(np.abs(half_freq_domain)==(max(np.abs(half_freq_domain))))[0][0]\n",
    "\n",
    "def meanFreq(data, n_bins=200):\n",
    "    \"\"\"\n",
    "    Weighted average of the frequency components to obtain a mean frequency\n",
    "    http://luscinia.sourceforge.net/page26/page35/page35.html\n",
    "    \"\"\"\n",
    "    mean_sig = np.ones_like(data)*np.mean(data)\n",
    "    # remove mean of the signal, for better results.\n",
    "    sig = data - mean_sig\n",
    "    freqsig = fft.fft(sig,n=n_bins) \n",
    "    half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "    return np.sum(np.abs(half_freq_domain) * range(len(half_freq_domain))) / sum(np.abs(half_freq_domain))\n",
    "\n",
    "def skewness(data):\n",
    "    return skew(data)\n",
    "\n",
    "def kurtos(data):\n",
    "    return kurtosis(data)\n",
    "\n",
    "def freq_skewness(data, n_bins=200): \n",
    "    \"\"\"skewness of the frequency domain signal\"\"\"\n",
    "    mean_sig = np.ones_like(data)*np.mean(data)\n",
    "    # remove mean of the signal, for better results.\n",
    "    sig = data - mean_sig\n",
    "    freqsig = fft.fft(sig,n=n_bins) \n",
    "    half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "    return skew(np.abs(half_freq_domain))\n",
    "\n",
    "def freq_kurtos(data, n_bins=200):\n",
    "    \"\"\"kurtosis of the frequency domain signal\"\"\"\n",
    "    mean_sig = np.ones_like(data)*np.mean(data)\n",
    "    # remove mean of the signal, for better results.\n",
    "    sig = data - mean_sig\n",
    "    freqsig = fft.fft(sig,n=n_bins) \n",
    "    half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "    return kurtosis(np.abs(half_freq_domain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function_dispatcher = {\n",
    "    \"mean\"     : mean,\n",
    "    \"std\"      : std,\n",
    "    \"max\"      : max_value,\n",
    "    \"min\"      : min_value,\n",
    "    \"mad\"      : mad,\n",
    "    \"sma\"      : sma,\n",
    "    \"iqr\"      : iqr,\n",
    "    \"energy\"   : energy,\n",
    "    \"maxInds\"  : maxInds,\n",
    "    \"meanFreq\" : meanFreq,\n",
    "    \"skewness\" : skewness,\n",
    "    \"kurtosis\" : kurtos,\n",
    "    \"freq_skewness\" : freq_skewness,\n",
    "    \"freq_kurtosis\" : freq_kurtos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metafeat_vector(segment, mf=[\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\n",
    "                                        \"iqr\",\"energy\",\"maxInds\",\"meanFreq\",\"skewness\",\"kurtosis\"]):\n",
    "    \"\"\"\n",
    "        Compute metafeatures from segment data.\n",
    "    \n",
    "        segment : the time series segment\n",
    "        mf      : list of metafeatures functions to be computed on the segment data.\n",
    "    \"\"\"\n",
    "    \n",
    "    meta_vector = OrderedDict()\n",
    "\n",
    "    for f in mf:\n",
    "        try:\n",
    "            func = function_dispatcher[f]          # retrieve function\n",
    "            meta_vector[f] = func(segment)    # compute function on segment.\n",
    "        except KeyError:\n",
    "            raise ValueError('Invalid function: {}'.format(f))\n",
    "\n",
    "    return meta_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load symbolized segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat_dir = './z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 29 mat Files found!\n"
     ]
    }
   ],
   "source": [
    "sym_dir = os.path.join(mat_dir, 'symbolization')\n",
    "files = getListOfFiles(sym_dir, \".mat\")\n",
    "print \">> {} mat Files found!\".format(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. of segments 623\n",
      "Min. sample size of 50\n"
     ]
    }
   ],
   "source": [
    "sym_segments = []\n",
    "sym_file_map = []\n",
    "count = 0\n",
    "min_length = float('inf')\n",
    "for f in files:\n",
    "    mat_content = sio.loadmat(os.path.join(sym_dir, f))\n",
    "    #print mat_content\n",
    "    data = mat_content['sym']\n",
    "    #print data.tolist()[0]\n",
    "    for d in data.tolist()[0]:\n",
    "        if d[0].size == 0:\n",
    "            pass\n",
    "        else:\n",
    "            count += 1\n",
    "            sample = [str(i[0]) for i in d.tolist()]\n",
    "            if len(sample) < min_length:\n",
    "                min_length = len(sample)\n",
    "            sample = ' '.join(map(str, sample)) # separate caracters by space\n",
    "            sym_segments.append(sample)\n",
    "            sym_file_map.append('.'.join(f.split('.')[0:2]))\n",
    "            \n",
    "\n",
    "assert (len(sym_segments) == count)\n",
    "print 'N. of segments {}'.format(count)\n",
    "print 'Min. sample size of {}'.format(min_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original recomposed signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 29 mat Files found!\n",
      ">> N. recovered signals 29\n"
     ]
    }
   ],
   "source": [
    "original_files = getListOfFiles(mat_dir, \".mat\")\n",
    "print \">> {} mat Files found!\".format(len(files))\n",
    "originalX = {}\n",
    "originalY = {}\n",
    "originalZ = {}\n",
    "for f in original_files:\n",
    "    mat_content = sio.loadmat(os.path.join(mat_dir, f))\n",
    "    originalX[f] = mat_content['x_axis'].tolist()[0]\n",
    "    originalY[f] = mat_content['y_axis'].tolist()[0]\n",
    "    originalZ[f] = mat_content['z_axis'].tolist()[0]\n",
    "\n",
    "original = originalZ \n",
    "print '>> N. recovered signals {}'.format(len(originalX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load signal segments files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 29 mat Files found!\n"
     ]
    }
   ],
   "source": [
    "seg_dir = os.path.join(mat_dir, 'segments')\n",
    "signal_files = getListOfFiles(seg_dir, \".mat\")\n",
    "print \">> {} mat Files found!\".format(len(files))\n",
    "original_files = []\n",
    "for f in files:\n",
    "    original_files.append('.'.join(f.split('.')[0:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realign segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 863), (1, 1092), (2, 618), (3, 736), (4, 1662), (5, 1591), (6, 1186), (7, 0), (8, 133), (9, 195), (10, 1385), (11, 1454), (12, 1526), (13, 1276), (14, 1332), (15, 268), (16, 358)]\n",
      "[863, 1092, 618, 736, 1662, 1591, 1186, 0, 133, 195, 1385, 1454, 1526, 1276, 1332, 268, 358]\n",
      "\n",
      "[(7, 0), (8, 133), (9, 195), (15, 268), (16, 358), (2, 618), (3, 736), (0, 863), (1, 1092), (6, 1186), (13, 1276), (14, 1332), (10, 1385), (11, 1454), (12, 1526), (5, 1591), (4, 1662)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1189), (1, 1250), (2, 153), (3, 714), (4, 1637), (5, 1510), (6, 1940), (7, 2033), (8, 291), (9, 391), (10, 495), (11, 0), (12, 77), (13, 1342), (14, 1421), (15, 549), (16, 664), (17, 1127), (18, 800), (19, 903)]\n",
      "[1189, 1250, 153, 714, 1637, 1510, 1940, 2033, 291, 391, 495, 0, 77, 1342, 1421, 549, 664, 1127, 800, 903]\n",
      "\n",
      "[(11, 0), (12, 77), (2, 153), (8, 291), (9, 391), (10, 495), (15, 549), (16, 664), (3, 714), (18, 800), (19, 903), (17, 1127), (0, 1189), (1, 1250), (13, 1342), (14, 1421), (5, 1510), (4, 1637), (6, 1940), (7, 2033)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 568), (1, 226), (2, 150), (3, 0), (4, 81), (5, 841), (6, 895), (7, 435), (8, 490), (9, 662), (10, 782)]\n",
      "[568, 226, 150, 0, 81, 841, 895, 435, 490, 662, 782]\n",
      "\n",
      "[(3, 0), (4, 81), (2, 150), (1, 226), (7, 435), (8, 490), (0, 568), (9, 662), (10, 782), (5, 841), (6, 895)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 387), (1, 247), (2, 0), (3, 598), (4, 817), (5, 980), (6, 1082), (7, 1289), (8, 1378), (9, 87), (10, 138), (11, 1652), (12, 1468), (13, 1529)]\n",
      "[387, 247, 0, 598, 817, 980, 1082, 1289, 1378, 87, 138, 1652, 1468, 1529]\n",
      "\n",
      "[(2, 0), (9, 87), (10, 138), (1, 247), (0, 387), (3, 598), (4, 817), (5, 980), (6, 1082), (7, 1289), (8, 1378), (12, 1468), (13, 1529), (11, 1652)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1961), (1, 798), (2, 1252), (3, 359), (4, 0), (5, 630), (6, 433), (7, 566), (8, 1488), (9, 1541), (10, 1593), (11, 1796), (12, 108), (13, 169), (14, 240), (15, 1303), (16, 1380)]\n",
      "[1961, 798, 1252, 359, 0, 630, 433, 566, 1488, 1541, 1593, 1796, 108, 169, 240, 1303, 1380]\n",
      "\n",
      "[(4, 0), (12, 108), (13, 169), (14, 240), (3, 359), (6, 433), (7, 566), (5, 630), (1, 798), (2, 1252), (15, 1303), (16, 1380), (8, 1488), (9, 1541), (10, 1593), (11, 1796), (0, 1961)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 850), (1, 950), (2, 1355), (3, 1477), (4, 441), (5, 744), (6, 0), (7, 67), (8, 1268), (9, 135), (10, 291), (11, 1573), (12, 1637), (13, 1689), (14, 2102), (15, 591), (16, 667), (17, 1968), (18, 2036), (19, 1043), (20, 1119), (21, 1189)]\n",
      "[850, 950, 1355, 1477, 441, 744, 0, 67, 1268, 135, 291, 1573, 1637, 1689, 2102, 591, 667, 1968, 2036, 1043, 1119, 1189]\n",
      "\n",
      "[(6, 0), (7, 67), (9, 135), (10, 291), (4, 441), (15, 591), (16, 667), (5, 744), (0, 850), (1, 950), (19, 1043), (20, 1119), (21, 1189), (8, 1268), (2, 1355), (3, 1477), (11, 1573), (12, 1637), (13, 1689), (17, 1968), (18, 2036), (14, 2102)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1121), (1, 2954), (2, 3271), (3, 945), (4, 1019), (5, 1695), (6, 1760), (7, 2379), (8, 2568), (9, 2692), (10, 757), (11, 1905), (12, 2059), (13, 1415), (14, 2785), (15, 2864), (16, 3340), (17, 3391), (18, 3090), (19, 3196), (20, 1504), (21, 1571), (22, 230), (23, 2211), (24, 2278), (25, 497), (26, 619), (27, 676), (28, 0), (29, 180), (30, 315), (31, 397)]\n",
      "[1121, 2954, 3271, 945, 1019, 1695, 1760, 2379, 2568, 2692, 757, 1905, 2059, 1415, 2785, 2864, 3340, 3391, 3090, 3196, 1504, 1571, 230, 2211, 2278, 497, 619, 676, 0, 180, 315, 397]\n",
      "\n",
      "[(28, 0), (29, 180), (22, 230), (30, 315), (31, 397), (25, 497), (26, 619), (27, 676), (10, 757), (3, 945), (4, 1019), (0, 1121), (13, 1415), (20, 1504), (21, 1571), (5, 1695), (6, 1760), (11, 1905), (12, 2059), (23, 2211), (24, 2278), (7, 2379), (8, 2568), (9, 2692), (14, 2785), (15, 2864), (1, 2954), (18, 3090), (19, 3196), (2, 3271), (16, 3340), (17, 3391)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 608), (1, 171), (2, 0), (3, 80), (4, 679), (5, 780), (6, 247), (7, 353), (8, 418), (9, 468), (10, 541), (11, 1140), (12, 1211), (13, 1298), (14, 886), (15, 1030)]\n",
      "[608, 171, 0, 80, 679, 780, 247, 353, 418, 468, 541, 1140, 1211, 1298, 886, 1030]\n",
      "\n",
      "[(2, 0), (3, 80), (1, 171), (6, 247), (7, 353), (8, 418), (9, 468), (10, 541), (0, 608), (4, 679), (5, 780), (14, 886), (15, 1030), (11, 1140), (12, 1211), (13, 1298)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 790), (1, 473), (2, 547), (3, 923), (4, 1125), (5, 1304), (6, 188), (7, 0), (8, 89), (9, 422), (10, 272), (11, 323)]\n",
      "[790, 473, 547, 923, 1125, 1304, 188, 0, 89, 422, 272, 323]\n",
      "\n",
      "[(7, 0), (8, 89), (6, 188), (10, 272), (11, 323), (9, 422), (1, 473), (2, 547), (0, 790), (3, 923), (4, 1125), (5, 1304)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 880), (1, 2000), (2, 1140), (3, 1214), (4, 281), (5, 696), (6, 1474), (7, 1547), (8, 616), (9, 407), (10, 1403), (11, 1295), (12, 1349), (13, 461), (14, 524), (15, 199), (16, 121), (17, 0), (18, 57), (19, 1655), (20, 1774), (21, 2096), (22, 2206)]\n",
      "[880, 2000, 1140, 1214, 281, 696, 1474, 1547, 616, 407, 1403, 1295, 1349, 461, 524, 199, 121, 0, 57, 1655, 1774, 2096, 2206]\n",
      "\n",
      "[(17, 0), (18, 57), (16, 121), (15, 199), (4, 281), (9, 407), (13, 461), (14, 524), (8, 616), (5, 696), (0, 880), (2, 1140), (3, 1214), (11, 1295), (12, 1349), (10, 1403), (6, 1474), (7, 1547), (19, 1655), (20, 1774), (1, 2000), (21, 2096), (22, 2206)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 466), (1, 122), (2, 200), (3, 1183), (4, 578), (5, 686), (6, 780), (7, 850), (8, 953), (9, 1072), (10, 0), (11, 51), (12, 316), (13, 382)]\n",
      "[466, 122, 200, 1183, 578, 686, 780, 850, 953, 1072, 0, 51, 316, 382]\n",
      "\n",
      "[(10, 0), (11, 51), (1, 122), (2, 200), (12, 316), (13, 382), (0, 466), (4, 578), (5, 686), (6, 780), (7, 850), (8, 953), (9, 1072), (3, 1183)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 668), (1, 988), (2, 173), (3, 1105), (4, 0), (5, 64), (6, 1424), (7, 1565), (8, 256), (9, 594), (10, 1673), (11, 1802), (12, 1901), (13, 1183), (14, 1302), (15, 540), (16, 339), (17, 429)]\n",
      "[668, 988, 173, 1105, 0, 64, 1424, 1565, 256, 594, 1673, 1802, 1901, 1183, 1302, 540, 339, 429]\n",
      "\n",
      "[(4, 0), (5, 64), (2, 173), (8, 256), (16, 339), (17, 429), (15, 540), (9, 594), (0, 668), (1, 988), (3, 1105), (13, 1183), (14, 1302), (6, 1424), (7, 1565), (10, 1673), (11, 1802), (12, 1901)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1988), (1, 2085), (2, 2206), (3, 2348), (4, 0), (5, 664), (6, 1061), (7, 1131), (8, 1321), (9, 1405), (10, 1756), (11, 479), (12, 421), (13, 256), (14, 350), (15, 59), (16, 142), (17, 1605), (18, 1659), (19, 1829), (20, 1896), (21, 757), (22, 986)]\n",
      "[1988, 2085, 2206, 2348, 0, 664, 1061, 1131, 1321, 1405, 1756, 479, 421, 256, 350, 59, 142, 1605, 1659, 1829, 1896, 757, 986]\n",
      "\n",
      "[(4, 0), (15, 59), (16, 142), (13, 256), (14, 350), (12, 421), (11, 479), (5, 664), (21, 757), (22, 986), (6, 1061), (7, 1131), (8, 1321), (9, 1405), (17, 1605), (18, 1659), (10, 1756), (19, 1829), (20, 1896), (0, 1988), (1, 2085), (2, 2206), (3, 2348)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1978), (1, 747), (2, 516), (3, 186), (4, 0), (5, 89), (6, 989), (7, 1098), (8, 1233), (9, 1684), (10, 1338), (11, 243), (12, 461), (13, 1543), (14, 1623), (15, 1791), (16, 1877)]\n",
      "[1978, 747, 516, 186, 0, 89, 989, 1098, 1233, 1684, 1338, 243, 461, 1543, 1623, 1791, 1877]\n",
      "\n",
      "[(4, 0), (5, 89), (3, 186), (11, 243), (12, 461), (2, 516), (1, 747), (6, 989), (7, 1098), (8, 1233), (10, 1338), (13, 1543), (14, 1623), (9, 1684), (15, 1791), (16, 1877), (0, 1978)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 2557), (1, 2253), (2, 3330), (3, 318), (4, 1257), (5, 719), (6, 801), (7, 1650), (8, 0), (9, 2057), (10, 2178), (11, 2392), (12, 2463), (13, 883), (14, 941), (15, 1061), (16, 1167), (17, 2710), (18, 2822), (19, 1985), (20, 406), (21, 474), (22, 2912), (23, 3042), (24, 1919), (25, 1743), (26, 1845), (27, 87), (28, 241), (29, 1580), (30, 1377), (31, 1482), (32, 551), (33, 669)]\n",
      "[2557, 2253, 3330, 318, 1257, 719, 801, 1650, 0, 2057, 2178, 2392, 2463, 883, 941, 1061, 1167, 2710, 2822, 1985, 406, 474, 2912, 3042, 1919, 1743, 1845, 87, 241, 1580, 1377, 1482, 551, 669]\n",
      "\n",
      "[(8, 0), (27, 87), (28, 241), (3, 318), (20, 406), (21, 474), (32, 551), (33, 669), (5, 719), (6, 801), (13, 883), (14, 941), (15, 1061), (16, 1167), (4, 1257), (30, 1377), (31, 1482), (29, 1580), (7, 1650), (25, 1743), (26, 1845), (24, 1919), (19, 1985), (9, 2057), (10, 2178), (1, 2253), (11, 2392), (12, 2463), (0, 2557), (17, 2710), (18, 2822), (22, 2912), (23, 3042), (2, 3330)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 165), (1, 1660), (2, 1744), (3, 1512), (4, 0), (5, 86), (6, 1353), (7, 1430), (8, 728), (9, 831), (10, 1113), (11, 507), (12, 382), (13, 436), (14, 601), (15, 666), (16, 1226), (17, 1292), (18, 959), (19, 1010)]\n",
      "[165, 1660, 1744, 1512, 0, 86, 1353, 1430, 728, 831, 1113, 507, 382, 436, 601, 666, 1226, 1292, 959, 1010]\n",
      "\n",
      "[(4, 0), (5, 86), (0, 165), (12, 382), (13, 436), (11, 507), (14, 601), (15, 666), (8, 728), (9, 831), (18, 959), (19, 1010), (10, 1113), (16, 1226), (17, 1292), (6, 1353), (7, 1430), (3, 1512), (1, 1660), (2, 1744)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 677), (1, 0), (2, 79), (3, 617), (4, 211), (5, 286), (6, 501), (7, 337), (8, 424)]\n",
      "[677, 0, 79, 617, 211, 286, 501, 337, 424]\n",
      "\n",
      "[(1, 0), (2, 79), (4, 211), (5, 286), (7, 337), (8, 424), (6, 501), (3, 617), (0, 677)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 357), (1, 408), (2, 470), (3, 0), (4, 58), (5, 209)]\n",
      "[357, 408, 470, 0, 58, 209]\n",
      "\n",
      "[(3, 0), (4, 58), (5, 209), (0, 357), (1, 408), (2, 470)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 0), (1, 571), (2, 287), (3, 423), (4, 101), (5, 179)]\n",
      "[0, 571, 287, 423, 101, 179]\n",
      "\n",
      "[(0, 0), (4, 101), (5, 179), (2, 287), (3, 423), (1, 571)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 3912), (1, 2793), (2, 1841), (3, 2712), (4, 1923), (5, 3186), (6, 768), (7, 975), (8, 2394), (9, 1331), (10, 1411), (11, 2114), (12, 3254), (13, 3779), (14, 2865), (15, 2949), (16, 0), (17, 53), (18, 1611), (19, 1785), (20, 1153), (21, 1271), (22, 355), (23, 3360), (24, 3412), (25, 2477), (26, 1986), (27, 2037), (28, 454), (29, 520), (30, 590), (31, 2554), (32, 2618), (33, 164), (34, 275), (35, 2211), (36, 2293), (37, 656), (38, 708), (39, 3467), (40, 3599)]\n",
      "[3912, 2793, 1841, 2712, 1923, 3186, 768, 975, 2394, 1331, 1411, 2114, 3254, 3779, 2865, 2949, 0, 53, 1611, 1785, 1153, 1271, 355, 3360, 3412, 2477, 1986, 2037, 454, 520, 590, 2554, 2618, 164, 275, 2211, 2293, 656, 708, 3467, 3599]\n",
      "\n",
      "[(16, 0), (17, 53), (33, 164), (34, 275), (22, 355), (28, 454), (29, 520), (30, 590), (37, 656), (38, 708), (6, 768), (7, 975), (20, 1153), (21, 1271), (9, 1331), (10, 1411), (18, 1611), (19, 1785), (2, 1841), (4, 1923), (26, 1986), (27, 2037), (11, 2114), (35, 2211), (36, 2293), (8, 2394), (25, 2477), (31, 2554), (32, 2618), (3, 2712), (1, 2793), (14, 2865), (15, 2949), (5, 3186), (12, 3254), (23, 3360), (24, 3412), (39, 3467), (40, 3599), (13, 3779), (0, 3912)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1684), (1, 2397), (2, 1806), (3, 1902), (4, 1250), (5, 723), (6, 1144), (7, 0), (8, 112), (9, 883), (10, 975), (11, 1060), (12, 220), (13, 329), (14, 2513), (15, 2668), (16, 3143), (17, 2806), (18, 3073), (19, 2898), (20, 3000), (21, 1545), (22, 1370), (23, 1471), (24, 638), (25, 420), (26, 516), (27, 3332), (28, 3395), (29, 2018), (30, 2148)]\n",
      "[1684, 2397, 1806, 1902, 1250, 723, 1144, 0, 112, 883, 975, 1060, 220, 329, 2513, 2668, 3143, 2806, 3073, 2898, 3000, 1545, 1370, 1471, 638, 420, 516, 3332, 3395, 2018, 2148]\n",
      "\n",
      "[(7, 0), (8, 112), (12, 220), (13, 329), (25, 420), (26, 516), (24, 638), (5, 723), (9, 883), (10, 975), (11, 1060), (6, 1144), (4, 1250), (22, 1370), (23, 1471), (21, 1545), (0, 1684), (2, 1806), (3, 1902), (29, 2018), (30, 2148), (1, 2397), (14, 2513), (15, 2668), (17, 2806), (19, 2898), (20, 3000), (18, 3073), (16, 3143), (27, 3332), (28, 3395)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 2587), (1, 1009), (2, 1647), (3, 841), (4, 2399), (5, 2510), (6, 1511), (7, 3111), (8, 3532), (9, 3193), (10, 282), (11, 542), (12, 2729), (13, 2821), (14, 2871), (15, 2942), (16, 1881), (17, 170), (18, 223), (19, 4019), (20, 3839), (21, 3644), (22, 3698), (23, 3292), (24, 3358), (25, 3433), (26, 2251), (27, 1977), (28, 2185), (29, 0), (30, 1408), (31, 1460), (32, 780), (33, 604), (34, 693), (35, 53), (36, 119), (37, 372), (38, 460), (39, 4330), (40, 4405)]\n",
      "[2587, 1009, 1647, 841, 2399, 2510, 1511, 3111, 3532, 3193, 282, 542, 2729, 2821, 2871, 2942, 1881, 170, 223, 4019, 3839, 3644, 3698, 3292, 3358, 3433, 2251, 1977, 2185, 0, 1408, 1460, 780, 604, 693, 53, 119, 372, 460, 4330, 4405]\n",
      "\n",
      "[(29, 0), (35, 53), (36, 119), (17, 170), (18, 223), (10, 282), (37, 372), (38, 460), (11, 542), (33, 604), (34, 693), (32, 780), (3, 841), (1, 1009), (30, 1408), (31, 1460), (6, 1511), (2, 1647), (16, 1881), (27, 1977), (28, 2185), (26, 2251), (4, 2399), (5, 2510), (0, 2587), (12, 2729), (13, 2821), (14, 2871), (15, 2942), (7, 3111), (9, 3193), (23, 3292), (24, 3358), (25, 3433), (8, 3532), (21, 3644), (22, 3698), (20, 3839), (19, 4019), (39, 4330), (40, 4405)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 2137), (1, 1588), (2, 1365), (3, 1490), (4, 0), (5, 270), (6, 341), (7, 1177), (8, 1303), (9, 1054), (10, 997), (11, 105), (12, 204), (13, 849), (14, 562), (15, 708), (16, 447), (17, 510)]\n",
      "[2137, 1588, 1365, 1490, 0, 270, 341, 1177, 1303, 1054, 997, 105, 204, 849, 562, 708, 447, 510]\n",
      "\n",
      "[(4, 0), (11, 105), (12, 204), (5, 270), (6, 341), (16, 447), (17, 510), (14, 562), (15, 708), (13, 849), (10, 997), (9, 1054), (7, 1177), (8, 1303), (2, 1365), (3, 1490), (1, 1588), (0, 2137)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1947), (1, 2031), (2, 1113), (3, 885), (4, 1718), (5, 1846), (6, 367), (7, 538), (8, 1219), (9, 1448), (10, 136), (11, 257), (12, 697), (13, 798), (14, 0), (15, 84), (16, 1558), (17, 1629)]\n",
      "[1947, 2031, 1113, 885, 1718, 1846, 367, 538, 1219, 1448, 136, 257, 697, 798, 0, 84, 1558, 1629]\n",
      "\n",
      "[(14, 0), (15, 84), (10, 136), (11, 257), (6, 367), (7, 538), (12, 697), (13, 798), (3, 885), (2, 1113), (8, 1219), (9, 1448), (16, 1558), (17, 1629), (4, 1718), (5, 1846), (0, 1947), (1, 2031)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 348), (1, 1141), (2, 505), (3, 1819), (4, 1907), (5, 2245), (6, 1960), (7, 2096), (8, 0), (9, 104), (10, 616), (11, 679), (12, 226), (13, 293), (14, 739), (15, 832), (16, 1033), (17, 884), (18, 956), (19, 1238), (20, 1644), (21, 1515), (22, 1582), (23, 1386), (24, 1446)]\n",
      "[348, 1141, 505, 1819, 1907, 2245, 1960, 2096, 0, 104, 616, 679, 226, 293, 739, 832, 1033, 884, 956, 1238, 1644, 1515, 1582, 1386, 1446]\n",
      "\n",
      "[(8, 0), (9, 104), (12, 226), (13, 293), (0, 348), (2, 505), (10, 616), (11, 679), (14, 739), (15, 832), (17, 884), (18, 956), (16, 1033), (1, 1141), (19, 1238), (23, 1386), (24, 1446), (21, 1515), (22, 1582), (20, 1644), (3, 1819), (4, 1907), (6, 1960), (7, 2096), (5, 2245)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 1815), (1, 0), (2, 509), (3, 347), (4, 101), (5, 891), (6, 999), (7, 1139), (8, 828), (9, 181), (10, 243), (11, 756), (12, 578), (13, 668), (14, 1587), (15, 1643), (16, 1237), (17, 1412)]\n",
      "[1815, 0, 509, 347, 101, 891, 999, 1139, 828, 181, 243, 756, 578, 668, 1587, 1643, 1237, 1412]\n",
      "\n",
      "[(1, 0), (4, 101), (9, 181), (10, 243), (3, 347), (2, 509), (12, 578), (13, 668), (11, 756), (8, 828), (5, 891), (6, 999), (7, 1139), (16, 1237), (17, 1412), (14, 1587), (15, 1643), (0, 1815)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 429), (1, 1469), (2, 827), (3, 919), (4, 2315), (5, 2387), (6, 2720), (7, 243), (8, 315), (9, 1038), (10, 1119), (11, 2989), (12, 3076), (13, 2156), (14, 2234), (15, 1743), (16, 1178), (17, 1331), (18, 1389), (19, 2775), (20, 2828), (21, 2927), (22, 527), (23, 1529), (24, 2049), (25, 1833), (26, 0), (27, 85), (28, 1928), (29, 1987), (30, 583), (31, 694), (32, 2499), (33, 2598), (34, 1602), (35, 1682), (36, 3163), (37, 3257)]\n",
      "[429, 1469, 827, 919, 2315, 2387, 2720, 243, 315, 1038, 1119, 2989, 3076, 2156, 2234, 1743, 1178, 1331, 1389, 2775, 2828, 2927, 527, 1529, 2049, 1833, 0, 85, 1928, 1987, 583, 694, 2499, 2598, 1602, 1682, 3163, 3257]\n",
      "\n",
      "[(26, 0), (27, 85), (7, 243), (8, 315), (0, 429), (22, 527), (30, 583), (31, 694), (2, 827), (3, 919), (9, 1038), (10, 1119), (16, 1178), (17, 1331), (18, 1389), (1, 1469), (23, 1529), (34, 1602), (35, 1682), (15, 1743), (25, 1833), (28, 1928), (29, 1987), (24, 2049), (13, 2156), (14, 2234), (4, 2315), (5, 2387), (32, 2499), (33, 2598), (6, 2720), (19, 2775), (20, 2828), (21, 2927), (11, 2989), (12, 3076), (36, 3163), (37, 3257)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 334), (1, 0), (2, 225), (3, 752), (4, 1153), (5, 849), (6, 1018), (7, 1084)]\n",
      "[334, 0, 225, 752, 1153, 849, 1018, 1084]\n",
      "\n",
      "[(1, 0), (2, 225), (0, 334), (3, 752), (5, 849), (6, 1018), (7, 1084), (4, 1153)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "[(0, 4253), (1, 2788), (2, 4865), (3, 0), (4, 1163), (5, 1853), (6, 4375), (7, 4563), (8, 678), (9, 4975), (10, 5049), (11, 1316), (12, 748), (13, 3458), (14, 3590), (15, 2535), (16, 5186), (17, 5292), (18, 1004), (19, 1100), (20, 1535), (21, 1603), (22, 3830), (23, 3901), (24, 3972), (25, 4026), (26, 3086), (27, 3180), (28, 330), (29, 489), (30, 4079), (31, 4130), (32, 3394), (33, 1693), (34, 1774), (35, 3270), (36, 3335), (37, 1399), (38, 1453), (39, 1970), (40, 2444), (41, 71), (42, 161), (43, 255), (44, 559), (45, 612), (46, 2595), (47, 2703), (48, 3681), (49, 3780), (50, 2219), (51, 2305), (52, 2059), (53, 2137)]\n",
      "[4253, 2788, 4865, 0, 1163, 1853, 4375, 4563, 678, 4975, 5049, 1316, 748, 3458, 3590, 2535, 5186, 5292, 1004, 1100, 1535, 1603, 3830, 3901, 3972, 4026, 3086, 3180, 330, 489, 4079, 4130, 3394, 1693, 1774, 3270, 3335, 1399, 1453, 1970, 2444, 71, 161, 255, 559, 612, 2595, 2703, 3681, 3780, 2219, 2305, 2059, 2137]\n",
      "\n",
      "[(3, 0), (41, 71), (42, 161), (43, 255), (28, 330), (29, 489), (44, 559), (45, 612), (8, 678), (12, 748), (18, 1004), (19, 1100), (4, 1163), (11, 1316), (37, 1399), (38, 1453), (20, 1535), (21, 1603), (33, 1693), (34, 1774), (5, 1853), (39, 1970), (52, 2059), (53, 2137), (50, 2219), (51, 2305), (40, 2444), (15, 2535), (46, 2595), (47, 2703), (1, 2788), (26, 3086), (27, 3180), (35, 3270), (36, 3335), (32, 3394), (13, 3458), (14, 3590), (48, 3681), (49, 3780), (22, 3830), (23, 3901), (24, 3972), (25, 4026), (30, 4079), (31, 4130), (0, 4253), (6, 4375), (7, 4563), (2, 4865), (9, 4975), (10, 5049), (16, 5186), (17, 5292)]\n",
      "-- Checking alignment for sequence...\n",
      "$$ Segments ALIGNED!\n",
      "Files list number: 623\n",
      "Min. sample size of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:19: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "sig_segments = []\n",
    "sig_file_map = []\n",
    "succ_alignments = []\n",
    "segment_fft = []\n",
    "min_length = float('inf')\n",
    "N_fft = 50\n",
    "for f in files:\n",
    "    mat_content = sio.loadmat(os.path.join(seg_dir, f))\n",
    "    data = mat_content['seg']\n",
    "    data = data.tolist()[0]\n",
    "    file_segments = []\n",
    "    for d in data:\n",
    "        if d[0].size == 0:\n",
    "            pass\n",
    "        else:\n",
    "            sample = [i[0] for i in d.tolist()]\n",
    "            file_segments.append(sample)\n",
    "            sample_fft = fft.fft(sample, n=N_fft)\n",
    "            segment_fft.append(np.abs(sample_fft[:len(sample_fft)/2]))\n",
    "            if len(sample) < min_length:\n",
    "                min_length = len(sample)\n",
    "    \n",
    "    ### aligning ###\n",
    "    alignment = []\n",
    "    for i,s in enumerate(file_segments):\n",
    "        alignment.append((i,find_subsequence(original[f],s)[0]))\n",
    "    print alignment\n",
    "    seq_align_indexes = [x[1] for x in alignment]\n",
    "    print seq_align_indexes\n",
    "    alignment.sort(key=lambda tup: tup[1])\n",
    "    print \n",
    "    print alignment\n",
    "    ### testing the realignment ###\n",
    "    print '-- Checking alignment for sequence...'\n",
    "    restored = [] \n",
    "    for l,i in alignment:\n",
    "        restored += file_segments[l]\n",
    "    try:\n",
    "        assert original[f] == restored\n",
    "        print '$$ Segments ALIGNED!'\n",
    "    except AssertionError:\n",
    "        print '%%%%% File {} FAILED to assert equality for aligned sequence %%%%%'.format(f)\n",
    "        break\n",
    "    \n",
    "    ### saving ###\n",
    "    for s in range(len(file_segments)):\n",
    "        sig_segments.append(file_segments[s])\n",
    "        sig_file_map.append('.'.join(f.split('.')[0:2]))\n",
    "        succ_alignments.append(seq_align_indexes[s])\n",
    "    \n",
    "    \n",
    "   \n",
    "    assert len(sig_segments) == len(sig_file_map) == len(succ_alignments)\n",
    "print 'Files list number: {}'.format(len(sig_segments))\n",
    "print 'Min. sample size of {}'.format(min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2137\n"
     ]
    }
   ],
   "source": [
    "print succ_alignments[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gridOfPlots(data, suptitle=\"Grid of plot\"):\n",
    "    \"\"\"Plots the data in a grid of plots.\n",
    "    Args:\n",
    "        data (list): the list of data to be used.\n",
    "        title (str): grid title.\n",
    "        columnToPlot: the column in the data to be plotted.\n",
    "    \"\"\"\n",
    "    \n",
    "    grid_side_size = int(round(np.sqrt(len(data))))\n",
    "    fig, axes = plt.subplots(grid_side_size, grid_side_size, figsize=(18,12))\n",
    "\n",
    "    count = 0\n",
    "    for i, row in enumerate(axes):\n",
    "        for j in range(grid_side_size):\n",
    "            if count >= len(data):\n",
    "                fig.delaxes(row[j])\n",
    "            else:\n",
    "                row[j].set_title(\"Plot {}\".format(count), fontsize=8, fontweight=\"bold\")\n",
    "                row[j].set_ylabel('g\\'s (9.8 m/s^2)')\n",
    "                row[j].plot(data[count])\n",
    "                row[j].grid()\n",
    "                count += 1\n",
    "\n",
    "    fig.suptitle(suptitle, fontsize=21)\n",
    "    fig.subplots_adjust(hspace=0.5, wspace= 0.4)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gridOfPlots(sig_segments[:50])\n",
    "#gridOfFFT(sig_segments[:50], 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize segments using metafeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12731454  0.02404791  0.1161499 ]\n",
      " [ 0.24158104  0.0800407   0.36096191]\n",
      " [ 0.22977978  0.07670215  0.29614258]\n",
      " ..., \n",
      " [ 0.02743816  0.00082736  0.00915527]\n",
      " [ 0.07537607  0.00800643  0.1259613 ]\n",
      " [ 0.05595584  0.0049847   0.0748291 ]]\n",
      "(623, 3)\n"
     ]
    }
   ],
   "source": [
    "## metafeatures list to be computed\n",
    "#to_compute = [\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\"iqr\",\"maxInds\",\"skewness\",\"kurtosis\",\"freq_skewness\",\"freq_kurtosis\"]\n",
    "#to_compute = [\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\"iqr\",\"skewness\",\"kurtosis\"]\n",
    "to_compute = [\"sma\", \"energy\",'iqr']\n",
    "meta_vectors = []\n",
    "for s in sig_segments:\n",
    "    meta_vectors.append(get_metafeat_vector(s, mf=to_compute).values())\n",
    "#X = np.matrix(meta_vectors)\n",
    "#X = np.matrix([i + [j] for i,j in zip(segment_fft,[max_value(x)-min_value(x) for x in sig_segments])])\n",
    "#max_min = np.array([max_value(x)-min_value(x) for x in sig_segments])\n",
    "#A = np.column_stack((np.array(segment_fft), max_min))\n",
    "#A = np.column_stack((np.array(A), meta_vectors))\n",
    "#A = np.column_stack((np.array(segment_fft), meta_vectors))\n",
    "X=np.matrix(meta_vectors)\n",
    "#X = np.matrix(A)\n",
    "print X\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard score normalization or Z-normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_normed = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "#print X_normed\n",
    "X = X_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linkage ward has a Cophenetic Correlation Coefficient of 0.816585932022\n",
      "Linkage single has a Cophenetic Correlation Coefficient of 0.422826185228\n",
      "Linkage complete has a Cophenetic Correlation Coefficient of 0.536013708854\n",
      "Linkage average has a Cophenetic Correlation Coefficient of 0.65008162575\n"
     ]
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "Z = None\n",
    "# Check the Cophenetic Correlation Coefficient of the clustering \n",
    "# with help of the cophenet() function. This (very very briefly)\n",
    "# compares (correlates) the actual pairwise distances of all samples \n",
    "# to those implied by the hierarchical clustering. The closer the value\n",
    "# is to 1, the better the clustering preserves the original distances.\n",
    "for t in ['ward','single', 'complete', 'average']:\n",
    "    # generate the linkage matrix\n",
    "    Z = linkage(X, t)\n",
    "    c, coph_dists = cophenet(Z, pdist(X, 'cosine'))\n",
    "    print 'Linkage {} has a Cophenetic Correlation Coefficient of {}'.format(t,c)\n",
    "Z = linkage(X,'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fancy_dendrogram(*args, **kwargs):\n",
    "    max_d = kwargs.pop('max_d', None)\n",
    "    if max_d and 'color_threshold' not in kwargs:\n",
    "        kwargs['color_threshold'] = max_d\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "    if not kwargs.get('no_plot', False):\n",
    "        plt.title('Hierarchical Clustering Dendrogram (FFT[200Fs,50bins],\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\"iqr\",\"skewness\",\"kurtosis\")')\n",
    "        plt.xlabel('sample index or (cluster size)')\n",
    "        plt.ylabel('distance')\n",
    "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "            x = 0.5 * sum(i[1:3])\n",
    "            y = d[1]\n",
    "            if y > annotate_above:\n",
    "                plt.plot(x, y, 'o', c=c)\n",
    "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                             textcoords='offset points',\n",
    "                             va='top', ha='center')\n",
    "        if max_d:\n",
    "            plt.axhline(y=max_d, c='k')\n",
    "    return ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fancy_dendrogram(\n",
    "    Z,\n",
    "    truncate_mode='lastp',\n",
    "    p=12,\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,\n",
    "    annotate_above=10,  # useful in small plots so annotations don't overlap\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get clusters by distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 209, 3: 163, 7: 83, 2: 53, 5: 52, 6: 48, 4: 15})\n"
     ]
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "max_d = 6\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "print Counter(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get clusters by max number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from scipy.cluster.hierarchy import fcluster\n",
    "#k=6\n",
    "#result = fcluster(Z, k, criterion='maxclust')\n",
    "#print Counter(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framming corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster counts: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    209\n",
       "3    163\n",
       "7     83\n",
       "2     53\n",
       "5     52\n",
       "6     48\n",
       "4     15\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = clusters.tolist()\n",
    "ranks = [i for i in range(len(sig_segments))]\n",
    "\n",
    "df = {'sym_segments':sym_segments,\n",
    "      'cluster':clusters,\n",
    "      'rank':ranks,\n",
    "      'sig_segments':sig_segments,\n",
    "      'sig_file_map':sig_file_map,\n",
    "      'sym_file_map':sym_file_map,\n",
    "      'alignment': succ_alignments\n",
    "     }\n",
    "\n",
    "frame = pd.DataFrame(df, index = [clusters] , columns = ['sym_segments','cluster','rank','sig_segments',\n",
    "                                                         'sig_file_map','sym_file_map', 'alignment'])\n",
    "assert frame['sig_file_map'].equals(frame['sym_file_map'])\n",
    "print 'Cluster counts: '\n",
    "frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using osx instead.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(X[:,0].tolist(), X[:,1].tolist(), X[:,2].tolist(), c=clusters, cmap='prism')  # plot points with cluster dependent colors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle DONE!\n"
     ]
    }
   ],
   "source": [
    "# open the file for writing\n",
    "file_name = 'cluster_info_matrix.pkl'\n",
    "file_object = open(file_name,'wb')\n",
    "pickle.dump(frame,file_object)\n",
    "file_object.close()\n",
    "print 'pickle DONE!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "1    404.750000\n",
       "2    193.550000\n",
       "3    266.087912\n",
       "4    328.452830\n",
       "5    313.370787\n",
       "6    351.142857\n",
       "7    447.866667\n",
       "8    323.500000\n",
       "9    312.000000\n",
       "Name: rank, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = frame['rank'].groupby(frame['cluster'])\n",
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c3c341542300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# we will also specify `random_state` so the plot is reproducible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMDS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdissimilarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"precomputed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape (n_components, n_samples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/manifold/mds.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, init)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdissimilarity\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"precomputed\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             warnings.warn(\"The MDS API has changed. ``fit`` now constructs an\"\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "MDS()\n",
    "# two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "xs, ys = pos[:, 0], pos[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing document clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up colors per clusters using a dict\n",
    "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
    "\n",
    "#set up cluster names using a dict\n",
    "cluster_names = {0: 'Cluster 1', \n",
    "                 1: 'Cluster 2', \n",
    "                 2: 'Cluster 3', \n",
    "                 3: 'Cluster 4', \n",
    "                 4: 'Cluster 5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=range(len(sym_segments)))) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "# set up plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=cluster_names[name], color=cluster_colors[name], mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         # changes apply to the y-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)  #show legend with only 1 point\n",
    "\n",
    "#add label in x,y position with the label as the film title\n",
    "for i in range(len(df)):\n",
    "    ax.text(df.ix[i]['x'], df.ix[i]['y'], df.ix[i]['title'], size=8)  \n",
    "\n",
    "    \n",
    "    \n",
    "plt.show() #show the plot\n",
    "\n",
    "#uncomment the below to save the plot if need be\n",
    "#plt.savefig('clusters_small_noaxes.png', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the file for writing\n",
    "file_name = 'cluster_info_matrix.pkl'\n",
    "file_object = open(file_name,'wb')\n",
    "pickle.dump(frame,file_object)\n",
    "file_object.close()\n",
    "print 'pickle DONE!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster's members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_side_size = 5\n",
    "fig, axes = plt.subplots(4, grid_side_size, figsize=(20,9))\n",
    "\n",
    "first_50 = defaultdict(list)\n",
    "for ind,c in enumerate(clusters):\n",
    "    axes[0][c].plot(sig_segments[ind])\n",
    "    axes[0][c].set_title('Cluster {}'.format(c))\n",
    "    first_50[c].append(sig_segments[ind][:50])\n",
    "    \n",
    "for c,l in first_50.iteritems():\n",
    "    sig = np.matrix(l)\n",
    "    mean_of_sig = np.mean(sig,axis=0).tolist()[0]\n",
    "    std_of_sig  = np.std(sig,axis=0).tolist()[0]\n",
    "    axes[1][c].errorbar(range(len(mean_of_sig)),mean_of_sig,yerr=std_of_sig, fmt='-o', ecolor='r')\n",
    "    axes[1][c].set_title('Mean of first 50 pts - Cluster {}'.format(c))\n",
    "    axes[1][c].plot(mean_of_sig, c='m')\n",
    "    \n",
    "N_fft = 100 # FFT number of bins\n",
    "Fs = 100 # Frequence range we are interested\n",
    "\n",
    "for c,l in first_50.iteritems():\n",
    "    # getting the signal (the mean value of each 50-length segment in the cluster). Assumed to be the\n",
    "    # mean of the cluster.\n",
    "    sig = np.mean(np.matrix(l),axis=0).tolist()[0]\n",
    "    mean_sig = np.ones_like(sig)*np.mean(sig)\n",
    "    # remove mean of the signal, for better results.\n",
    "    sig = sig - mean_sig\n",
    "    ### FFT\n",
    "    freqsig = fft.fft(sig, n=N_fft)\n",
    "    freq_axis = np.arange(0, Fs, Fs / N_fft)\n",
    "    axes[2][c].plot(freq_axis, np.abs(freqsig), lw=2.0, c='b')\n",
    "    p = plt.Rectangle((Fs/2, 0), Fs/2, ax.get_ylim()[1], facecolor=\"grey\", fill=True, alpha=0.75, hatch=\"/\", zorder=3)\n",
    "    axes[2][c].add_patch(p)\n",
    "    axes[2][c].set_xlim((-2,Fs))\n",
    "    axes[2][c].set_xlim((-2,Fs))\n",
    "    axes[2][c].set_title(\"FFT - Cluster{}\".format(c), fontsize=10)\n",
    "    axes[2][c].set_ylabel('Power')\n",
    "    axes[2][c].set_xlabel('Frequency (Hz)')\n",
    "    axes[2][c].legend((p,), ('excluded',))\n",
    "    axes[2][c].grid()\n",
    "\n",
    "for cc in range(len(cluster_centers)):\n",
    "    axes[3][cc].plot(cluster_centers[cc])\n",
    "    axes[3][cc].set_title('Centroid of cluster {}'.format(cc))\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.8, wspace=0.5)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical document clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I was successfuly able to cluster and plot the documents using k-means, I wanted to try another clustering algorithm. I chose the [Ward clustering algorithm](http://en.wikipedia.org/wiki/Ward%27s_method) because it offers hierarchical clustering. Ward clustering is an agglomerative clustering method, meaning that at each stage, the pair of clusters with minimum between-cluster distance are merged. I used the precomputed cosine distance matrix (*dist*) to calculate a linkage_matrix, which I then plot as a dendrogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "\n",
    "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 20)) # set size\n",
    "ax = dendrogram(linkage_matrix, orientation=\"right\", labels=range(len(segments)))\n",
    "\n",
    "plt.tick_params(\\\n",
    "    axis= 'x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off')\n",
    "\n",
    "plt.tight_layout() #show plot with tight layout\n",
    "\n",
    "#uncomment below to save figure\n",
    "plt.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "ncomps = 10\n",
    "svd = TruncatedSVD(n_components=ncomps)\n",
    "svd_fit = svd.fit(smatrix.todense())\n",
    "Y = svd.fit_transform(smatrix.todense()) \n",
    "ax = pd.Series(svd_fit.explained_variance_ratio_.cumsum()).plot(kind='line', figsize=(10,3)).set_ylim([0,1.1])\n",
    "print('Variance preserved by first 50 components == {:.2%}'.format(\n",
    "        svd_fit.explained_variance_ratio_.cumsum()[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfsvd = pd.DataFrame(Y, columns=['c{}'.format(c) for c in range(ncomps)], index=frame.index)\n",
    "print(dfsvd.shape)\n",
    "dfsvd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotdims = 5\n",
    "ploteorows = 1\n",
    "svdcols = [c for c in dfsvd.columns if c[0] == 'c']\n",
    "dfsvdplot = dfsvd[svdcols].iloc[:,:plotdims]\n",
    "dfsvdplot['cluster'] = frame['cluster']\n",
    "ax = sns.pairplot(dfsvdplot.iloc[::ploteorows,:], hue='cluster', size=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z = TSNE().fit_transform(dfsvd[svdcols])\n",
    "dftsne = pd.DataFrame(Z, columns=['x','y'], index=dfsvd.index)\n",
    "ax = sns.lmplot('x', 'y', dftsne, fit_reg=False, size=8\n",
    "                ,scatter_kws={'alpha':0.7,'s':60})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftsne['cluster'] = frame['cluster']\n",
    "g = sns.lmplot('x', 'y', dftsne, hue='cluster', fit_reg=False, size=8\n",
    "                ,scatter_kws={'alpha':0.7,'s':60})\n",
    "g.axes.flat[0].set_title('Scatterplot of a 20D dataset reduced to 2D using t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import dbscan\n",
    "db_a = dbscan(tfidf_matrix,eps=0.60, min_samples=3)\n",
    "clusters = db_a[1].tolist()\n",
    "ranks = [i for i in range(len(segments))]\n",
    "ndf = {'indexes' : range(len(segments)), 'segments': segments,'cluster': clusters, 'rank': ranks}\n",
    "nframe = pd.DataFrame(ndf, index = [clusters] , columns = ['indexes','segments','cluster','rank'])\n",
    "nframe['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncomps = 10\n",
    "svd = TruncatedSVD(n_components=ncomps)\n",
    "svd_fit = svd.fit(smatrix.todense())\n",
    "Y = svd.fit_transform(smatrix.todense()) \n",
    "ax = pd.Series(svd_fit.explained_variance_ratio_.cumsum()).plot(kind='line', figsize=(10,3)).set_ylim([0,1.1])\n",
    "print('Variance preserved by first 50 components == {:.2%}'.format(\n",
    "        svd_fit.explained_variance_ratio_.cumsum()[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfsvd = pd.DataFrame(Y, columns=['c{}'.format(c) for c in range(ncomps)], index=nframe.index)\n",
    "print(dfsvd.shape)\n",
    "dfsvd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotdims = 5\n",
    "ploteorows = 1\n",
    "dfsvdplot = dfsvd[svdcols].iloc[:,:plotdims]\n",
    "dfsvdplot['cluster'] = nframe['cluster']\n",
    "ax = sns.pairplot(dfsvdplot.iloc[::ploteorows,:], hue='cluster', size=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svdcols = [c for c in dfsvd.columns if c[0] == 'c']\n",
    "Z = TSNE().fit_transform(dfsvd[svdcols])\n",
    "dftsne = pd.DataFrame(Z, columns=['x','y'], index=dfsvd.index)\n",
    "ax = sns.lmplot('x', 'y', dftsne, fit_reg=False, size=8\n",
    "                ,scatter_kws={'alpha':0.7,'s':60})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftsne['cluster'] = nframe['cluster']\n",
    "g = sns.lmplot('x', 'y', dftsne, hue='cluster', fit_reg=False, size=8\n",
    "                ,scatter_kws={'alpha':0.7,'s':60})\n",
    "g.axes.flat[0].set_title('Scatterplot of a 20D dataset reduced to 2D using t-SNE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
