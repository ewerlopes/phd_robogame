{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from pandas.tools.plotting import lag_plot, autocorrelation_plot\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.stats import norm, skew, kurtosis\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "import scipy.fftpack as fft\n",
    "\n",
    "from helper_functions import getListOfFiles, getCSV, getStatistics, remap_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> 34 CSV Files found:\n",
      "\n",
      "[\"_2016-11-23-18-49-13_exp1_Player.csv\", \"_2016-11-23-18-49-13_exp2_Player.csv\", \"_2016-11-23-18-49-13_exp3_Player.csv\", \"_2016-11-23-18-49-13_exp4_Player.csv\", \"_2016-11-23-18-49-13_exp5_Player.csv\", \"_2016-11-24-15-43-37_exp1d_Player.csv\", \"_2016-11-24-15-43-37_exp2d_Player.csv\", \"_2016-11-24-15-43-37_exp3d_Player.csv\", \"_2016-11-24-15-43-37_exp4d_Player.csv\", \"_2016-11-24-15-43-37_exp5d_Player.csv\", \"_2016-11-24-15-43-37_exp6d_Player.csv\", \"_2016-11-24-16-23-29_expa_Player.csv\", \"_2016-11-24-16-23-29_expb_Player.csv\", \"_2016-11-24-16-23-29_expc_Player.csv\", \"_2016-11-24-16-23-29_expd_Player.csv\", \"_2016-11-24-16-48-48_exp1d_Player.csv\", \"_2016-11-24-16-48-48_exp2d_Player.csv\", \"_2016-11-24-16-48-48_exp3d_Player.csv\", \"_2016-11-24-17-15-38_expa_Player.csv\", \"_2016-11-24-17-15-38_expb_Player.csv\", \"_2016-11-24-17-15-38_expc_Player.csv\", \"_2016-11-24-17-40-06_expb_Player.csv\", \"_2016-11-26-15-42-51_exp1d_Player.csv\", \"_2016-11-26-16-05-47_exp1d_Player.csv\", \"_2016-11-26-16-35-21_exp1d_Player.csv\", \"_2016-11-26-16-49-44_exp1d_Player.csv\", \"_2016-11-26-17-15-53_exp2_Player.csv\", \"_2016-11-26-17-15-53_exp3_Player.csv\", \"_2016-11-26-17-15-53_exp4_Player.csv\", \"_2016-11-26-17-15-53_fixed_exp1d_Player.csv\", \"_2016-11-26-17-15-53_fixed_exp2d_Player.csv\", \"_2016-11-26-17-38-21_fixed_exp1d_Player.csv\", \"_2016-11-26-18-36-15_expa_Player.csv\", \"_2016-11-26-18-36-15_expb_Player.csv\"]\n"
     ]
    }
   ],
   "source": [
    "csv_dir = \"./data\"\n",
    "files = getListOfFiles(csv_dir, \".csv\")\n",
    "print \">> {} CSV Files found:\\n\".format(len(files))\n",
    "print json.dumps(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a dictionary containing a remap of the name of the features. This is to easy visualization since ros feature names may be very long and also allow quick decoupled modifications (just edit the variable locally). Also, from it we define a ignore list containing the names we do not want to consider for the analysis. That is done by setting to the ignore list all dictionary keys with empty values. **Here we assume the names are consistent feature name w.r.t. the `csv` data. Otherwise, a `ValueError` exception is likely to be thrown!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of ignored topics: []\n"
     ]
    }
   ],
   "source": [
    "# variable for storing the loaded feature names.\n",
    "feature_name_map = {\n",
    "  \"time\" : \"time\",\n",
    "  \"Control\": \"control\",\n",
    "  \"High_level\": \"high_level\",\n",
    "  \"Expectation\": \"expectation\",\n",
    "  \"Activity\": \"activity\",\n",
    "  \"/kinect_features/.ci\": \"ci\",\n",
    "  \"/kinect_features/.distance\": \"distance\",\n",
    "  \"/kinect_features/.proximity\": \"proximity\",\n",
    "  \"robogame/imu_state.gyro.x\": \"gyroX\",\n",
    "  \"robogame/imu_state.gyro.y\": \"gyroY\",\n",
    "  \"robogame/imu_state.gyro.z\": \"gyroZ\",\n",
    "  \"robogame/imu_state.linear_acc.x\": \"accX\",\n",
    "  \"robogame/imu_state.linear_acc.y\": \"accY\",\n",
    "  \"robogame/imu_state.linear_acc.z\": \"accZ\"\n",
    "}\n",
    "\n",
    "ignore_col_list = [k for k,v in feature_name_map.items() if v is \"\"]\n",
    "print \"List of ignored topics: {}\".format(ignore_col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-features function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-127-b2f0cf1309e4>, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-127-b2f0cf1309e4>\"\u001b[0;36m, line \u001b[0;32m59\u001b[0m\n\u001b[0;31m    if data.shape[0] == 0\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def mean(data):\n",
    "    \"\"\"Calculates mean of the data\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.mean(axis=0, skipna=True, numeric_only=True).round(2) for d in data]\n",
    "    else:\n",
    "        return data.mean(axis=0, skipna=True)\n",
    "\n",
    "\n",
    "def std(data):\n",
    "    \"\"\"Calculates the standard deviation\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.std(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.std(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "\n",
    "def max_value(data):\n",
    "    \"\"\" Calculates Largest value in array\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.max(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.max(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "    \n",
    "def min_value(data):\n",
    "    \"\"\"Calculates smallest value in array\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.min(axis=0, skipna=True, numeric_only=True) for d in data]\n",
    "    else:\n",
    "        return data.min(axis=0, skipna=True, numeric_only=True)\n",
    "\n",
    "\n",
    "def mad(data):\n",
    "    \"\"\" Calculates the median absolute deviation\"\"\"\n",
    "    if isinstance(data,list):\n",
    "        l = []\n",
    "        for d in data:\n",
    "            m = {}\n",
    "            for k in data._get_numeric_data():\n",
    "                m[k] = abs(data[k].dropna() - data[k].median())\n",
    "                m[k] = pd.Series(m[k]).median()\n",
    "            l.append(pd.Series(m))\n",
    "        return l\n",
    "    else:\n",
    "        m = {}\n",
    "        for k in data._get_numeric_data():\n",
    "            m[k] = abs(data[k].dropna() - data[k].median())\n",
    "            m[k] = pd.Series(m[k]).median()\n",
    "        return pd.Series(m)\n",
    "\n",
    "\n",
    "def sma(data):\n",
    "    \"\"\"Computes Signal magnitude area.\n",
    "    http://dsp.stackexchange.com/questions/18649/signal-magnitude-area\n",
    "    \"\"\"\n",
    "    if isinstance(data,list):\n",
    "        return [d.sum(axis=0, skipna=True, numeric_only=True) / data.shape[0] for d in data]\n",
    "    else:\n",
    "        if data.shape[0] == 0\n",
    "            raise ValueError('Error')\n",
    "        return data.sum(axis=0, skipna=True, numeric_only=True) / data.shape[0]\n",
    "\n",
    "\n",
    "def energy(data):\n",
    "    \"\"\"Energy measure. Sum of the squares divided by the number of values.\"\"\"\n",
    "    for d in data:\n",
    "        row = data[np.isfinite(data[d])].apply(lambda x: x**2).mean(axis=0, skipna=True)\n",
    "    return pd.Series(row)\n",
    "\n",
    "def iqr(data):\n",
    "    \"\"\"Calculates the interquartile range\n",
    "    http://stackoverflow.com/questions/23228244/how-do-you-find-the-iqr-in-numpy\n",
    "    \"\"\"\n",
    "    if isinstance(data,np.ndarray):\n",
    "        return np.subtract(*np.percentile(data, [75, 25]))\n",
    "    else:\n",
    "        v = {}\n",
    "        for k in data._get_numeric_data():\n",
    "            v[k] = np.subtract(*np.percentile(data[k].dropna(), [75, 25]))\n",
    "        return pd.Series(v)\n",
    "\n",
    "def entropy(data):\n",
    "    \"\"\"Signal entropy\"\"\"\n",
    "    pass\n",
    "\n",
    "def maxInds(data, n_bins=200, filterMean= True):\n",
    "    \"\"\"Returns the index of the frequency component with largest magnitude\"\"\"\n",
    "    m_indexes = {}\n",
    "    for k in data._get_numeric_data():\n",
    "        c_sig = []\n",
    "        if filterMean:\n",
    "            filtered = data[k].dropna().as_matrix()\n",
    "            mean_sig = np.ones_like(filtered)*np.mean(filtered)\n",
    "            # remove mean of the signal, for better results.\n",
    "            c_sig = data[k].dropna().as_matrix() - mean_sig\n",
    "        freqsig = fft.fft(c_sig,n=n_bins) \n",
    "        half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "        #get index in the freq domain\n",
    "        m_indexes[k] = np.where(np.abs(half_freq_domain)==(max(np.abs(half_freq_domain))))[0][0]\n",
    "    return pd.Series(m_indexes)\n",
    "\n",
    "def meanFreq(data, n_bins=200, filterMean=True):\n",
    "    \"\"\"\n",
    "    Weighted average of the frequency components to obtain a mean frequency\n",
    "    http://luscinia.sourceforge.net/page26/page35/page35.html\n",
    "    \"\"\"\n",
    "    m_freq = {}\n",
    "    for k in data._get_numeric_data():\n",
    "        c_sig = []\n",
    "        if filterMean:\n",
    "            filtered = data[k].dropna().as_matrix()\n",
    "            mean_sig = np.ones_like(filtered)*np.mean(filtered)\n",
    "            # remove mean of the signal, for better results.\n",
    "            c_sig = data[k].dropna().as_matrix() - mean_sig\n",
    "        freqsig = fft.fft(c_sig,n=n_bins) \n",
    "        half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "        #get index in the freq domain\n",
    "        m_freq[k] = np.sum(np.abs(half_freq_domain) * range(len(half_freq_domain))) / sum(np.abs(half_freq_domain))\n",
    "    return pd.Series(m_freq)\n",
    "\n",
    "def skewness(data, n_bins=200, filterMean=True): \n",
    "    \"\"\"skewness of the frequency domain signal\"\"\"\n",
    "    m_skew = {}\n",
    "    for k in data._get_numeric_data():\n",
    "        c_sig = []\n",
    "        if filterMean:\n",
    "            filtered = data[k].dropna().as_matrix()\n",
    "            mean_sig = np.ones_like(filtered)*np.mean(filtered)\n",
    "            # remove mean of the signal, for better results.\n",
    "            c_sig = data[k].dropna().as_matrix() - mean_sig\n",
    "        freqsig = fft.fft(c_sig,n=n_bins) \n",
    "        half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "        #get index in the freq domain\n",
    "        m_skew[k] = skew(c_sig)\n",
    "    return pd.Series(m_skew)\n",
    "\n",
    "def kurtos(data, n_bins=200, filterMean=True):\n",
    "    \"\"\"kurtosis of the frequency domain signal\"\"\"\n",
    "    m_kurtosis = {}\n",
    "    for k in data._get_numeric_data():\n",
    "        c_sig = []\n",
    "        if filterMean:\n",
    "            filtered = data[k].dropna().as_matrix()\n",
    "            mean_sig = np.ones_like(filtered)*np.mean(filtered)\n",
    "            # remove mean of the signal, for better results.\n",
    "            c_sig = data[k].dropna().as_matrix() - mean_sig\n",
    "        freqsig = fft.fft(c_sig,n=n_bins) \n",
    "        half_freq_domain = freqsig[:int(n_bins/2)]\n",
    "        #get index in the freq domain\n",
    "        m_kurtosis[k] = kurtosis(c_sig)\n",
    "    return pd.Series(m_kurtosis)\n",
    "\n",
    "def bandsEnergy():\n",
    "    \"\"\"Energy of a frequency interval within the bins of the FFT.\"\"\"\n",
    "    pass\n",
    "\n",
    "def angle():\n",
    "    \"\"\"Angle between to vectors.\"\"\"\n",
    "    pass\n",
    "\n",
    "def arCoeff(): \n",
    "    \"\"\"Autorregresion coefficients with Burg order equal to 4\"\"\"\n",
    "    pass\n",
    "\n",
    "def correlation_acc(data): \n",
    "    \"\"\"correlation coefficient between two accelerometer signals\"\"\"\n",
    "    cor = data[[\"accY\", \"accX\", \"accZ\", \"gyroZ\", \"gyroX\", \"gyroY\"]].corr().to_dict()['accY']\n",
    "    res = {}\n",
    "    for k,v in cor.iteritems():\n",
    "        if k == 'accY':\n",
    "            continue\n",
    "        res[k+'-accY'] = v\n",
    "    return res\n",
    "\n",
    "def correlation_kinect(data): \n",
    "    \"\"\"correlation coefficient between two accelerometer signals\"\"\"\n",
    "    cor = flatten_dict(data[[\"ci\",\"proximity\"]].corr().to_dict()[\"ci\"])\n",
    "    res = {}\n",
    "    for k,v in cor.iteritems():\n",
    "        if k == 'ci':\n",
    "            continue\n",
    "        res[k+'-ci'] = v\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadFile(file_name, verbose=False):\n",
    "    ##NOTE: IF \"TOO MANY VALUES TO UNPACK\" ERROR IN THE getCSV METHOD, RESTART THE KERNEL. SOMETHING MUST BE WRONG WITH\n",
    "    # THE KERNEL INITIALIZATION. MUST BE CHECKED! (LOW-PRIORITY)\n",
    "\n",
    "    csv_data = None          # the variable where the loaded csv data is stored.\n",
    "    num_windows = 0          # the number of windows loaded.\n",
    "    windows = []             # the list of windows data. Each element is a pandas dataframe \n",
    "                             #  corresponding to the windows. The list is of size 'num_windows'.\n",
    "\n",
    "    print '-- Processing: \"{}\"'.format(file_name)\n",
    "\n",
    "    # load the data, abort in case of error.\n",
    "    try:\n",
    "        num_windows, csv_data = getCSV(os.path.join(csv_dir, file_name))\n",
    "    except ValueError as e:\n",
    "        print traceback.format_exc()\n",
    "        sys.exit(-1)\n",
    "\n",
    "    for w in range(num_windows):\n",
    "        win_data = {}\n",
    "        for k in csv_data.keys():\n",
    "            # consider the data only if it is not in the ignore list.\n",
    "            if k not in ignore_col_list:\n",
    "                if  csv_data[k][w] == []:\n",
    "                    raise ValueError(\"\\tFile has empty tagged windows. Skipping...\")\n",
    "                win_data[feature_name_map[k]] = csv_data[k][w]\n",
    "                \n",
    "        # convert dictionary to dataframe and save it to list of all windows data for the file.\n",
    "        windows.append(pd.DataFrame.from_dict(win_data))\n",
    "    \n",
    "    print '-- Retrieved {} windows in {}'.format(num_windows, file_name)\n",
    "    \n",
    "    if verbose:\n",
    "        overlap_reference = 50\n",
    "        try:\n",
    "            _, n_windows, sample_info, avg_overlap, avg_diff = getStatistics(csv_data, compareWith=overlap_reference)\n",
    "            print \"LOAD SUMMARY:\"\n",
    "            print tabulate([[n_windows,\"{:.2f}\".format(avg_overlap),\"{:.2f}\".format(avg_diff)]],\n",
    "                               headers=[\"#Win\", \"Avg. Overlap\", \"Avg. dev. from ref.\"])\n",
    "        except ValueError as e:\n",
    "            print traceback.format_exc()\n",
    "            return None\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def flatten_dict(dd, separator='.', prefix=''):\n",
    "        \"\"\"This function collapses a dictionary into a list, by appending\n",
    "        the keys' values to themselves. That is, parents(keys) are joined together\n",
    "        with children (values) by the separator variable.\n",
    "        dd  :   dictionary to be flattened\n",
    "        separator   :   the character used to join values to their keys.\n",
    "        prefix      :   the character used in place of the value.\n",
    "        \"\"\"\n",
    "        return {prefix + separator + k if prefix else k: v\n",
    "                for kk, vv in dd.items()\n",
    "                for k, v in flatten_dict(vv, separator, kk).items()\n",
    "                } if isinstance(dd, dict) else {prefix: dd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MetafeatureRow():\n",
    "    \"\"\"Upon call to store, organize the data in \n",
    "    a dictionary. Convenient for using with csv.DictWriter.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.rows = defaultdict(dict)\n",
    "\n",
    "    def store(self,d,func):\n",
    "        \"\"\"Each new value of a function is stored in a list\n",
    "        for the given attibute.\"\"\"\n",
    "        for k,v in d.items():\n",
    "            self.rows[k][func] = float(\"{:.2f}\".format(v))\n",
    "        \n",
    "    def getData(self):\n",
    "        \"\"\"Return dictionary where each key is the atribute\n",
    "        and its value a dictionary containing the metafeatures\n",
    "        calculated\"\"\"\n",
    "        return self.rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One single window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Processing: \"_2016-11-23-18-49-13_exp1_Player.csv\"\n",
      "-- Retrieved 24 windows in _2016-11-23-18-49-13_exp1_Player.csv\n",
      "*******************************************************************************************************************\n",
      "                                             META-FEATURES - 1 windows\n",
      "*******************************************************************************************************************\n",
      "\n",
      "topics        mean      std    max    min    mad      sma     iqr       energy    maxInds    meanFreq    skewness\n",
      "---------  -------  -------  -----  -----  -----  -------  ------  -----------  ---------  ----------  ----------\n",
      "accX       -336.07  2733.65   7531  -6422   1769  -262.78    3740  7.53493e+06          1       15.23        0.41\n",
      "accY        478.14  1280.78   7809  -1476    426   373.87   922.5  1.85785e+06          9       23.25         3.5\n",
      "accZ       1697.15  2723.27   8636  -7714   1075  1327.03  2187.5  1.02461e+07         13       22.98        -0.5\n",
      "ci            0.23     0.22   0.66      0   0.27     0.05    0.38          0.1          4          27        0.24\n",
      "distance      0.36     0.31   0.68      0   0.13     0.08    0.63         0.22          4       23.12       -0.26\n",
      "gyroX         1.22    26.31    136    -63     14     0.96    28.5       688.91         13       29.49        0.69\n",
      "gyroY       -12.97    35.28     42   -117     19   -10.14      44         1404          2       24.98       -0.97\n",
      "gyroZ        -6.41    18.54     50    -66     12    -5.02      23       382.66          1       26.44       -0.59\n",
      "proximity     0.51     0.43   0.92      0   0.03     0.11    0.87         0.44          4       24.73       -0.34\n",
      "time          3.03     0.87    4.5    1.5   0.75     3.03     1.5         9.96          1       18.42       -0.06\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "topics       kurtosis\n",
      "---------  ----------\n",
      "accX            -0.05\n",
      "accY            16.44\n",
      "accZ             2.32\n",
      "ci              -1.19\n",
      "distance        -1.85\n",
      "gyroX            4.11\n",
      "gyroY            0.32\n",
      "gyroZ               1\n",
      "proximity       -1.88\n",
      "time             -1.2\n",
      "{\n",
      "    \"gyroZ-accY\": -0.094078801980469487, \n",
      "    \"gyroY-accY\": -0.044084433850772618, \n",
      "    \"gyroX-accY\": -0.026180097723216483, \n",
      "    \"accZ-accY\": 0.34130655164265505, \n",
      "    \"accX-accY\": 0.24960090677224611\n",
      "}\n",
      "{\n",
      "    \"proximity-ci\": 0.9091868500076794\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class tabularData():\n",
    "    def __init__(self):\n",
    "        self.rows = defaultdict(list)\n",
    "        self.headers = ['topics']\n",
    "\n",
    "    def store(self,d,func):\n",
    "        \"\"\"Each new value of a function is stored in a list\n",
    "        for the given attibute.\"\"\"\n",
    "        for k,v in d.items():\n",
    "            self.rows[k].append(float(\"{:.2f}\".format(v)))\n",
    "        self.headers.append(func)\n",
    "        \n",
    "    def getData(self):\n",
    "        r = []\n",
    "        for k,v in self.rows.items():\n",
    "            r.append([k] + [i for i in v])\n",
    "        return sorted(r)\n",
    "    \n",
    "    def getHeaders(self):\n",
    "        return self.headers\n",
    "\n",
    "try:\n",
    "    data = loadFile(files[0])[1]._get_numeric_data()\n",
    "except ValueError as e:\n",
    "    print traceback.format_exc()\n",
    "\n",
    "\n",
    "table_rows = tabularData()\n",
    "table_rows.store(mean(data).to_dict(), \"mean\")\n",
    "table_rows.store(std(data).to_dict(), \"std\")\n",
    "table_rows.store(max_value(data).to_dict(), \"max\")\n",
    "table_rows.store(min_value(data).to_dict(), \"min\")\n",
    "table_rows.store(mad(data).to_dict(), \"mad\")\n",
    "table_rows.store(sma(data).to_dict(), \"sma\")\n",
    "table_rows.store(iqr(data).to_dict(), \"iqr\")\n",
    "table_rows.store(energy(data).to_dict(), \"energy\")\n",
    "table_rows.store(maxInds(data).to_dict(), \"maxInds\")\n",
    "table_rows.store(meanFreq(data).to_dict(), \"meanFreq\")\n",
    "table_rows.store(skewness(data).to_dict(), \"skewness\")\n",
    "\n",
    "table_rows2 = tabularData()\n",
    "table_rows2.store(kurtos(data).to_dict(), \"kurtosis\")\n",
    "\n",
    "print 115 * '*'\n",
    "print 45*' '+\"META-FEATURES - 1 windows\"\n",
    "print 115 * '*'\n",
    "print    \n",
    "print tabulate(table_rows.getData(), headers=table_rows.getHeaders(), numalign=\"right\")\n",
    "print 115 * '-'\n",
    "print tabulate(table_rows2.getData(), headers=table_rows2.getHeaders(), numalign=\"right\")\n",
    "\n",
    "print json.dumps(correlation_acc(data), indent=4)\n",
    "print json.dumps(correlation_kinect(data),indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_metadata(data, target=\"control\", all_targets=['control','expectation','high_level','activity'],):\n",
    "    \"\"\"Export the metadata to a file\n",
    "    data : the list of windows data.\n",
    "    target   :   the target we want to export\n",
    "    \"\"\"\n",
    "    numeric_cols = data[0]._get_numeric_data().columns.values\n",
    "    exclude = list(set(['control','expectation','high_level','activity']) - set(['control'])) + ['time']\n",
    "    \n",
    "    X_output_filename = open(\"{}_X.csv\".format(target), 'wa')\n",
    "    y_output_filename = open(\"{}_y.csv\".format(target), 'wa')\n",
    "        \n",
    "    Xwriter = csv.DictWriter(X_output_filename, [k for k in numeric_cols if k not in exclude])\n",
    "    # write the headers\n",
    "    Xwriter.writeheader()\n",
    "    # flush data\n",
    "    X_output_filename.flush()\n",
    "    ywriter = csv.writer(y_output_filename)\n",
    "    ywriter.writerow([target])\n",
    "    for df in data:\n",
    "        rows = mean(df).to_dict()\n",
    "        del rows[\"time\"]\n",
    "        Xwriter.writerows([rows])   #write content to the file\n",
    "        #Xwriter.writerows([{}])    #write an empty line to mark the end of the windows\n",
    "        X_output_filename.flush()   #flush data.\n",
    "        ywriter.writerow([df[target][0]])\n",
    "        y_output_filename.flush()\n",
    "    \n",
    "\n",
    "def getMetadataForAll(listOfFiles, target=\"control\", all_targets=['control','expectation','high_level','activity'],\n",
    "                     mf=[\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\"iqr\",\"energy\",\"maxInds\",\"meanFreq\",\"skewness\",\"kurtosis\"]):\n",
    "    \"\"\"Export the metadata to a file\n",
    "    data : the list of windows data.\n",
    "    target   :   the target we want to export\n",
    "    \"\"\"\n",
    "    \n",
    "    exclude = list(set(all_targets) - set(target)) + ['time']\n",
    "    X_output_filename = None\n",
    "    y_output_filename = None\n",
    "    Xwriter = None\n",
    "    ywriter = None\n",
    "    data = []\n",
    "    failed_files = []\n",
    "    \n",
    "    for i, csv_filename in enumerate(listOfFiles):\n",
    "        try:\n",
    "            file_data = loadFile(csv_filename)\n",
    "        except ValueError as e:\n",
    "            print traceback.format_exc()\n",
    "            failed_files.append(csv_filename)\n",
    "            continue\n",
    "        \n",
    "        if i == 0:\n",
    "            numeric_cols = file_data[0]._get_numeric_data().columns.values\n",
    "            \n",
    "            attributes = dict.fromkeys([k for k in numeric_cols if k not in exclude])\n",
    "            for k in attributes.keys():\n",
    "                attributes[k] = dict.fromkeys([\"mean\",\"std\",\"max\",\"min\",\"mad\",\"sma\",\"iqr\",\n",
    "                                               \"energy\",\"maxInds\",\"meanFreq\",\"skewness\",\"kurtosis\"])\n",
    "        \n",
    "            X_output_filename = open(\"{}_X.csv\".format(target), 'wa')\n",
    "            #y_output_filename = open(\"{}_y.csv\".format(target), 'wa')\n",
    "\n",
    "            Xwriter = csv.DictWriter(X_output_filename, flatten_dict(attributes,separator='_').keys() + [target])\n",
    "            # write the headers\n",
    "            Xwriter.writeheader()\n",
    "            # flush data\n",
    "            X_output_filename.flush()\n",
    "            #ywriter = csv.writer(y_output_filename)\n",
    "            #ywriter.writerow([target])\n",
    "            \n",
    "        for win_df in file_data:\n",
    "            win_df_numeric = win_df._get_numeric_data()\n",
    "            meta_row = MetafeatureRow()\n",
    "            meta_row.store(mean(win_df_numeric.drop('time', 1)).to_dict(), \"mean\")\n",
    "            meta_row.store(std(win_df_numeric.drop('time', 1)).to_dict(), \"std\")\n",
    "            meta_row.store(max_value(win_df_numeric.drop('time', 1)).to_dict(), \"max\")\n",
    "            meta_row.store(min_value(win_df_numeric.drop('time', 1)).to_dict(), \"min\")\n",
    "            meta_row.store(mad(win_df_numeric.drop('time', 1)).to_dict(), \"mad\")\n",
    "            meta_row.store(sma(win_df_numeric.drop('time', 1)).to_dict(), \"sma\")\n",
    "            meta_row.store(iqr(win_df_numeric.drop('time', 1)).to_dict(), \"iqr\")\n",
    "            meta_row.store(energy(win_df_numeric.drop('time', 1)).to_dict(), \"energy\")\n",
    "            meta_row.store(maxInds(win_df_numeric.drop('time', 1)).to_dict(), \"maxInds\")\n",
    "            #meta_row.store(meanFreq(win_df_numeric.drop('time', 1)).to_dict(), \"meanFreq\")\n",
    "            meta_row.store(skewness(win_df_numeric.drop('time', 1)).to_dict(), \"skewness\")\n",
    "            meta_row.store(kurtos(win_df_numeric.drop('time', 1)).to_dict(), \"kurtosis\")\n",
    "\n",
    "            rows = flatten_dict(meta_row.getData(),separator='_')\n",
    "            rows[target] = win_df[target][0]\n",
    "            Xwriter.writerows([rows])   #write content to the file\n",
    "            X_output_filename.flush()   #flush data.\n",
    "            #ywriter.writerow([win_df[target][0]])\n",
    "            #y_output_filename.flush()\n",
    "        \n",
    "        ### write an empty line to mark the end of the file\n",
    "        Xwriter.writerows([{}])\n",
    "        X_output_filename.flush()\n",
    "        #ywriter.writerows([\"\"])\n",
    "        #y_output_filename.flush()\n",
    "        print \"Meta-features saved to file!\"\n",
    "        print\n",
    "        #############################\n",
    "    X_output_filename.close()\n",
    "    print '-- List of failed files:\\n{} '.format(json.dumps(failed_files, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Processing: \"_2016-11-23-18-49-13_exp1_Player.csv\"\n",
      "-- Retrieved 24 windows in _2016-11-23-18-49-13_exp1_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-23-18-49-13_exp2_Player.csv\"\n",
      "-- Retrieved 28 windows in _2016-11-23-18-49-13_exp2_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-23-18-49-13_exp3_Player.csv\"\n",
      "-- Retrieved 12 windows in _2016-11-23-18-49-13_exp3_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-23-18-49-13_exp4_Player.csv\"\n",
      "-- Retrieved 23 windows in _2016-11-23-18-49-13_exp4_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-23-18-49-13_exp5_Player.csv\"\n",
      "-- Retrieved 27 windows in _2016-11-23-18-49-13_exp5_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-15-43-37_exp1d_Player.csv\"\n",
      "-- Retrieved 31 windows in _2016-11-24-15-43-37_exp1d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-15-43-37_exp2d_Player.csv\"\n",
      "-- Retrieved 48 windows in _2016-11-24-15-43-37_exp2d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-15-43-37_exp3d_Player.csv\"\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-152-ddfee205139c>\", line 46, in getMetadataForAll\n",
      "    file_data = loadFile(csv_filename)\n",
      "  File \"<ipython-input-117-be9ddeed8f5a>\", line 25, in loadFile\n",
      "    raise ValueError(\"\\tFile has empty tagged windows. Skipping...\")\n",
      "ValueError: \tFile has empty tagged windows. Skipping...\n",
      "\n",
      "-- Processing: \"_2016-11-24-15-43-37_exp4d_Player.csv\"\n",
      "-- Retrieved 18 windows in _2016-11-24-15-43-37_exp4d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-15-43-37_exp5d_Player.csv\"\n",
      "-- Retrieved 18 windows in _2016-11-24-15-43-37_exp5d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-15-43-37_exp6d_Player.csv\"\n",
      "-- Retrieved 30 windows in _2016-11-24-15-43-37_exp6d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-16-23-29_expa_Player.csv\"\n",
      "-- Retrieved 16 windows in _2016-11-24-16-23-29_expa_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-16-23-29_expb_Player.csv\"\n",
      "-- Retrieved 26 windows in _2016-11-24-16-23-29_expb_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-16-23-29_expc_Player.csv\"\n",
      "-- Retrieved 32 windows in _2016-11-24-16-23-29_expc_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-16-23-29_expd_Player.csv\"\n",
      "-- Retrieved 29 windows in _2016-11-24-16-23-29_expd_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-16-48-48_exp1d_Player.csv\"\n",
      "-- Retrieved 46 windows in _2016-11-24-16-48-48_exp1d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-16-48-48_exp2d_Player.csv\"\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-152-ddfee205139c>\", line 46, in getMetadataForAll\n",
      "    file_data = loadFile(csv_filename)\n",
      "  File \"<ipython-input-117-be9ddeed8f5a>\", line 25, in loadFile\n",
      "    raise ValueError(\"\\tFile has empty tagged windows. Skipping...\")\n",
      "ValueError: \tFile has empty tagged windows. Skipping...\n",
      "\n",
      "-- Processing: \"_2016-11-24-16-48-48_exp3d_Player.csv\"\n",
      "-- Retrieved 24 windows in _2016-11-24-16-48-48_exp3d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-17-15-38_expa_Player.csv\"\n",
      "-- Retrieved 22 windows in _2016-11-24-17-15-38_expa_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-17-15-38_expb_Player.csv\"\n",
      "-- Retrieved 15 windows in _2016-11-24-17-15-38_expb_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-17-15-38_expc_Player.csv\"\n",
      "-- Retrieved 18 windows in _2016-11-24-17-15-38_expc_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-24-17-40-06_expb_Player.csv\"\n",
      "-- Retrieved 54 windows in _2016-11-24-17-40-06_expb_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-15-42-51_exp1d_Player.csv\"\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-152-ddfee205139c>\", line 46, in getMetadataForAll\n",
      "    file_data = loadFile(csv_filename)\n",
      "  File \"<ipython-input-117-be9ddeed8f5a>\", line 25, in loadFile\n",
      "    raise ValueError(\"\\tFile has empty tagged windows. Skipping...\")\n",
      "ValueError: \tFile has empty tagged windows. Skipping...\n",
      "\n",
      "-- Processing: \"_2016-11-26-16-05-47_exp1d_Player.csv\"\n",
      "-- Retrieved 46 windows in _2016-11-26-16-05-47_exp1d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-16-35-21_exp1d_Player.csv\"\n",
      "-- Retrieved 61 windows in _2016-11-26-16-35-21_exp1d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-16-49-44_exp1d_Player.csv\"\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-152-ddfee205139c>\", line 46, in getMetadataForAll\n",
      "    file_data = loadFile(csv_filename)\n",
      "  File \"<ipython-input-117-be9ddeed8f5a>\", line 25, in loadFile\n",
      "    raise ValueError(\"\\tFile has empty tagged windows. Skipping...\")\n",
      "ValueError: \tFile has empty tagged windows. Skipping...\n",
      "\n",
      "-- Processing: \"_2016-11-26-17-15-53_exp2_Player.csv\"\n",
      "-- Retrieved 32 windows in _2016-11-26-17-15-53_exp2_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-17-15-53_exp3_Player.csv\"\n",
      "-- Retrieved 28 windows in _2016-11-26-17-15-53_exp3_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-17-15-53_exp4_Player.csv\"\n",
      "-- Retrieved 32 windows in _2016-11-26-17-15-53_exp4_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-17-15-53_fixed_exp1d_Player.csv\"\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-152-ddfee205139c>\", line 46, in getMetadataForAll\n",
      "    file_data = loadFile(csv_filename)\n",
      "  File \"<ipython-input-117-be9ddeed8f5a>\", line 25, in loadFile\n",
      "    raise ValueError(\"\\tFile has empty tagged windows. Skipping...\")\n",
      "ValueError: \tFile has empty tagged windows. Skipping...\n",
      "\n",
      "-- Processing: \"_2016-11-26-17-15-53_fixed_exp2d_Player.csv\"\n",
      "-- Retrieved 25 windows in _2016-11-26-17-15-53_fixed_exp2d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-17-38-21_fixed_exp1d_Player.csv\"\n",
      "-- Retrieved 45 windows in _2016-11-26-17-38-21_fixed_exp1d_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-18-36-15_expa_Player.csv\"\n",
      "-- Retrieved 19 windows in _2016-11-26-18-36-15_expa_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- Processing: \"_2016-11-26-18-36-15_expb_Player.csv\"\n",
      "-- Retrieved 72 windows in _2016-11-26-18-36-15_expb_Player.csv\n",
      "Meta-features saved to file!\n",
      "\n",
      "-- List of failed files:\n",
      "[\n",
      "    \"_2016-11-24-15-43-37_exp3d_Player.csv\", \n",
      "    \"_2016-11-24-16-48-48_exp2d_Player.csv\", \n",
      "    \"_2016-11-26-15-42-51_exp1d_Player.csv\", \n",
      "    \"_2016-11-26-16-49-44_exp1d_Player.csv\", \n",
      "    \"_2016-11-26-17-15-53_fixed_exp1d_Player.csv\"\n",
      "] \n"
     ]
    }
   ],
   "source": [
    "getMetadataForAll(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
